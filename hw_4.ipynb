{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 4 - 10 баллов\n",
    "\n",
    "В этом задании вам предстоит дообучить трансформерную модель для NER-задачи в различных форматах:\n",
    "\n",
    "1. Обучите NER-модель\n",
    "\n",
    "- Загрузите набор данных [Collection5](https://github.com/natasha/corus?tab=readme-ov-file#load_ne5) - **1 балл**\n",
    "- Разбейте набор данных на train/test части\n",
    "- Дообучите модель [rubert-tiny2](https://huggingface.co/cointegrated/rubert-tiny2) на train-части корпуса для решения NER-задачи, сделайте замеры качества NER-метрик до и после дообучения - **2 балла**\n",
    "\n",
    "2. Попробуйте улучшить качество модели следующими способами:\n",
    "- Предварительно дообучите на train-части в MLM режиме, а потом дообучите на NER-задачу - **2 балла**\n",
    "- Сгенерируйте синтетическую разметку* подходящего**, на ваш взгляд, новостного корпуса большой и умной моделью для русскоязычного NER***, а затем использовав ее для дообучения rubert-tiny2 вместе с основным набором данных - **2 балла**\n",
    "\n",
    "3. Финально сравните результаты различных подходов - **1 балл**\n",
    "\n",
    "*прогоните датасет через NER-модель, получите ее предсказания и используйте их в качестве резметки\n",
    "\n",
    "**Можно использовать уже знакомый вам датасет lenta-ru, объем данных лучше взять от 10_000 текстов\n",
    "\n",
    "***Например, можно взять модель модель DeepPavlov ner_collection3_bert. Инструкция по запуску есть в [документации](https://docs.deeppavlov.ai/en/master/features/models/NER.html)\n",
    "\n",
    "**Общее**\n",
    "\n",
    "- Принимаемые решения обоснованы (почему выбрана определенная архитектура/гиперпараметр/оптимизатор/преобразование и т.п.) - **1 балл**\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **1 балл**\n",
    "\n",
    "**Формат сдачи ДЗ**\n",
    "\n",
    "- Каждая домашняя работа – PR в отдельную ветку **hw_n**, где **n** - номер домашней работы\n",
    "- Добавить ментора и pacifikus в reviewers\n",
    "- Дождаться ревью, если все ок – мержим в main\n",
    "- Если не ок – вносим исправления и снова отправляем на ревью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    AutoModelForMaskedLM,\n",
    ")\n",
    "import evaluate\n",
    "from razdel import tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from corus import load_ne5, load_lenta\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Обучение NER модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/ner/Collection5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ne5Markup(\n",
       "    id='001',\n",
       "    text='Россия рассчитывает на конструктивное воздействие США на Грузию\\r\\n\\r\\n04/08/2008 12:08\\r\\n\\r\\nМОСКВА, 4 авг - РИА Новости. Россия рассчитывает, что США воздействуют на Тбилиси в связи с обострением ситуации в зоне грузино-осетинского конфликта. Об этом статс-секретарь - заместитель министра иностранных дел России Григорий Карасин заявил в телефонном разговоре с заместителем госсекретаря США Дэниэлом Фридом.\\r\\n\\r\\n\"С российской стороны выражена глубокая озабоченность в связи с новым витком напряженности вокруг Южной Осетии, противозаконными действиями грузинской стороны по наращиванию своих вооруженных сил в регионе, бесконтрольным строительством фортификационных сооружений\", - говорится в сообщении.\\r\\n\\r\\n\"Россия уже призвала Тбилиси к ответственной линии и рассчитывает также на конструктивное воздействие со стороны Вашингтона\", - сообщил МИД России. ',\n",
       "    spans=[Ne5Span(\n",
       "         index='T1',\n",
       "         type='GEOPOLIT',\n",
       "         start=0,\n",
       "         stop=6,\n",
       "         text='Россия'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T2',\n",
       "         type='GEOPOLIT',\n",
       "         start=50,\n",
       "         stop=53,\n",
       "         text='США'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T3',\n",
       "         type='GEOPOLIT',\n",
       "         start=57,\n",
       "         stop=63,\n",
       "         text='Грузию'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T4',\n",
       "         type='LOC',\n",
       "         start=87,\n",
       "         stop=93,\n",
       "         text='МОСКВА'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T5',\n",
       "         type='MEDIA',\n",
       "         start=103,\n",
       "         stop=114,\n",
       "         text='РИА Новости'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T6',\n",
       "         type='GEOPOLIT',\n",
       "         start=116,\n",
       "         stop=122,\n",
       "         text='Россия'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T7',\n",
       "         type='GEOPOLIT',\n",
       "         start=141,\n",
       "         stop=144,\n",
       "         text='США'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T8',\n",
       "         type='GEOPOLIT',\n",
       "         start=161,\n",
       "         stop=168,\n",
       "         text='Тбилиси'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T9',\n",
       "         type='GEOPOLIT',\n",
       "         start=301,\n",
       "         stop=307,\n",
       "         text='России'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T10',\n",
       "         type='PER',\n",
       "         start=308,\n",
       "         stop=324,\n",
       "         text='Григорий Карасин'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T11',\n",
       "         type='GEOPOLIT',\n",
       "         start=383,\n",
       "         stop=386,\n",
       "         text='США'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T12',\n",
       "         type='PER',\n",
       "         start=387,\n",
       "         stop=402,\n",
       "         text='Дэниэлом Фридом'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T13',\n",
       "         type='GEOPOLIT',\n",
       "         start=505,\n",
       "         stop=517,\n",
       "         text='Южной Осетии'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T14',\n",
       "         type='GEOPOLIT',\n",
       "         start=703,\n",
       "         stop=709,\n",
       "         text='Россия'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T15',\n",
       "         type='GEOPOLIT',\n",
       "         start=723,\n",
       "         stop=730,\n",
       "         text='Тбилиси'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T16',\n",
       "         type='GEOPOLIT',\n",
       "         start=815,\n",
       "         stop=825,\n",
       "         text='Вашингтона'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T17',\n",
       "         type='ORG',\n",
       "         start=838,\n",
       "         stop=841,\n",
       "         text='МИД'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T18',\n",
       "         type='GEOPOLIT',\n",
       "         start=842,\n",
       "         stop=848,\n",
       "         text='России'\n",
       "     )]\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(load_ne5(DATA_PATH))\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER 10623\n",
      "[('Дмитрий Медведев', 159), ('Д.Медведев', 116), ('Владимир Путин', 80)]\n",
      "ORG 7033\n",
      "[('МВД', 321), ('Единой России', 111), ('Госдумы', 98)]\n",
      "GEOPOLIT 4104\n",
      "[('РФ', 734), ('России', 483), ('США', 423)]\n",
      "LOC 3140\n",
      "[('Москвы', 224), ('Московской области', 102), ('Москве', 86)]\n",
      "MEDIA 1509\n",
      "[('РИА Новости', 180), ('СМИ', 155), ('ИА REGNUM', 128)]\n"
     ]
    }
   ],
   "source": [
    "type2text = defaultdict(Counter)\n",
    "ents = Counter()\n",
    "for item in corpus:\n",
    "    for e in item.spans:\n",
    "        ents[e.type] += 1\n",
    "        type2text[e.type][e.text] += 1\n",
    "\n",
    "for k, v in ents.most_common():\n",
    "    print(k, v)\n",
    "    print(type2text[k].most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(item):\n",
    "    raw_toks = list(tokenize(item.text))\n",
    "    words = [tok.text for tok in raw_toks]\n",
    "    word_labels = [\"O\"] * len(raw_toks)\n",
    "    char2word = [None] * len(item.text)\n",
    "    for i, word in enumerate(raw_toks):\n",
    "        char2word[word.start : word.stop] = [i] * len(word.text)\n",
    "\n",
    "    for e in item.spans:\n",
    "        e_words = sorted({idx for idx in char2word[e.start : e.stop] if idx is not None})\n",
    "        word_labels[e_words[0]] = \"B-\" + e.type\n",
    "        for idx in e_words[1:]:\n",
    "            word_labels[idx] = \"I-\" + e.type\n",
    "\n",
    "    return {\"tokens\": words, \"tags\": word_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Россия', 'рассчитывает', 'на', 'конструктивное', 'воздействие', 'США', 'на', 'Грузию', '04/08/2008', '12', ':', '08', 'МОСКВА', ',', '4', 'авг', '-', 'РИА', 'Новости', '.', 'Россия', 'рассчитывает', ',', 'что', 'США', 'воздействуют', 'на', 'Тбилиси', 'в', 'связи', 'с', 'обострением', 'ситуации', 'в', 'зоне', 'грузино-осетинского', 'конфликта', '.', 'Об', 'этом', 'статс-секретарь', '-', 'заместитель', 'министра', 'иностранных', 'дел', 'России', 'Григорий', 'Карасин', 'заявил', 'в', 'телефонном', 'разговоре', 'с', 'заместителем', 'госсекретаря', 'США', 'Дэниэлом', 'Фридом', '.', '\"', 'С', 'российской', 'стороны', 'выражена', 'глубокая', 'озабоченность', 'в', 'связи', 'с', 'новым', 'витком', 'напряженности', 'вокруг', 'Южной', 'Осетии', ',', 'противозаконными', 'действиями', 'грузинской', 'стороны', 'по', 'наращиванию', 'своих', 'вооруженных', 'сил', 'в', 'регионе', ',', 'бесконтрольным', 'строительством', 'фортификационных', 'сооружений', '\"', ',', '-', 'говорится', 'в', 'сообщении', '.', '\"', 'Россия', 'уже', 'призвала', 'Тбилиси', 'к', 'ответственной', 'линии', 'и', 'рассчитывает', 'также', 'на', 'конструктивное', 'воздействие', 'со', 'стороны', 'Вашингтона', '\"', ',', '-', 'сообщил', 'МИД', 'России', '.'], 'tags': ['B-GEOPOLIT', 'O', 'O', 'O', 'O', 'B-GEOPOLIT', 'O', 'B-GEOPOLIT', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-MEDIA', 'I-MEDIA', 'O', 'B-GEOPOLIT', 'O', 'O', 'O', 'B-GEOPOLIT', 'O', 'O', 'B-GEOPOLIT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GEOPOLIT', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GEOPOLIT', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GEOPOLIT', 'I-GEOPOLIT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GEOPOLIT', 'O', 'O', 'B-GEOPOLIT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GEOPOLIT', 'O', 'O', 'O', 'O', 'B-ORG', 'B-GEOPOLIT', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(extract_labels(corpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data = [extract_labels(item) for item in corpus]\n",
    "ner_train, ner_test = train_test_split(ner_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-GEOPOLIT',\n",
       " 'B-LOC',\n",
       " 'B-MEDIA',\n",
       " 'B-ORG',\n",
       " 'B-PER',\n",
       " 'I-GEOPOLIT',\n",
       " 'I-LOC',\n",
       " 'I-MEDIA',\n",
       " 'I-ORG',\n",
       " 'I-PER']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = sorted({label for item in ner_train for label in item[\"tags\"]})\n",
    "if \"O\" in label_list:\n",
    "    label_list.remove(\"O\")\n",
    "    label_list = [\"O\"] + label_list\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data = DatasetDict(\n",
    "    {\"train\": Dataset.from_pandas(pd.DataFrame(ner_train)), \"test\": Dataset.from_pandas(pd.DataFrame(ner_test))}\n",
    ")\n",
    "ner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"cointegrated/rubert-tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    tokenized_inputs = ner_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        label_ids = [label_list.index(idx) if isinstance(idx, str) else idx for idx in label_ids]\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8369f6761274201a7bce2a9aa0bfeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bf6b28350f4b16b59bb1b9a85bef2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ner_datasets = ner_data.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ner_model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(label_list))\n",
    "ner_model.config.id2label = dict(enumerate(label_list))\n",
    "ner_model.config.label2id = {v: k for k, v in ner_model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data_collator = DataCollatorForTokenClassification(ner_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels, zero_division=0)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# больщинство аргументов с пары, не вижу смысла их обосновывать\n",
    "ner_args = TrainingArguments(\n",
    "    output_dir=\"ner\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    run_name=\"ner\",\n",
    "    logging_steps=1,\n",
    ")\n",
    "\n",
    "ner_trainer = Trainer(\n",
    "    model=ner_model,\n",
    "    args=ner_args,\n",
    "    train_dataset=tokenized_ner_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_ner_datasets[\"test\"],\n",
    "    processing_class=ner_tokenizer,\n",
    "    data_collator=ner_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretty_metrics(data):\n",
    "    # Отдельные таблицы\n",
    "    train_entities = {\n",
    "        k.split(\"_\")[-1]: v for k, v in data.items() if k.startswith(\"eval_train_\") and isinstance(v, dict)\n",
    "    }\n",
    "    test_entities = {k.split(\"_\")[-1]: v for k, v in data.items() if k.startswith(\"eval_test_\") and isinstance(v, dict)}\n",
    "\n",
    "    train_df = pd.DataFrame(train_entities).T\n",
    "    test_df = pd.DataFrame(test_entities).T\n",
    "\n",
    "    # Таблица общих метрик\n",
    "    train_overall = {\n",
    "        k.replace(\"eval_train_\", \"\"): v\n",
    "        for k, v in data.items()\n",
    "        if k.startswith(\"eval_train_\") and not isinstance(v, dict)\n",
    "    }\n",
    "    test_overall = {\n",
    "        k.replace(\"eval_test_\", \"\"): v\n",
    "        for k, v in data.items()\n",
    "        if k.startswith(\"eval_test_\") and not isinstance(v, dict)\n",
    "    }\n",
    "\n",
    "    overall_df = pd.DataFrame([train_overall, test_overall], index=[\"Train\", \"Test\"]).T\n",
    "\n",
    "    # Вывод\n",
    "    print(\"\\n=== Метрики по сущностям (Train) ===\")\n",
    "    print(train_df.round(4))\n",
    "\n",
    "    print(\"\\n=== Метрики по сущностям (Test) ===\")\n",
    "    print(test_df.round(4))\n",
    "\n",
    "    print(\"\\n=== Общие метрики ===\")\n",
    "    print(overall_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Метрики по сущностям (Train) ===\n",
      "          precision  recall      f1   number\n",
      "GEOPOLIT     0.0079  0.0338  0.0128   4736.0\n",
      "LOC          0.0105  0.0713  0.0182   6440.0\n",
      "MEDIA        0.0034  0.0602  0.0065   2708.0\n",
      "ORG          0.0472  0.2346  0.0786  13890.0\n",
      "PER          0.0348  0.1832  0.0585  15204.0\n",
      "\n",
      "=== Метрики по сущностям (Test) ===\n",
      "          precision  recall      f1  number\n",
      "GEOPOLIT     0.0062  0.0279  0.0101  1111.0\n",
      "LOC          0.0099  0.0738  0.0175  1436.0\n",
      "MEDIA        0.0034  0.0571  0.0064   718.0\n",
      "ORG          0.0478  0.2255  0.0789  3548.0\n",
      "PER          0.0361  0.1940  0.0609  3871.0\n",
      "\n",
      "=== Общие метрики ===\n",
      "                          Train     Test\n",
      "loss                     2.5079   2.5070\n",
      "model_preparation_time   0.0000   0.0000\n",
      "overall_precision        0.0262   0.0265\n",
      "overall_recall           0.1588   0.1618\n",
      "overall_f1               0.0450   0.0455\n",
      "overall_accuracy         0.0673   0.0673\n",
      "runtime                  8.4738   2.1827\n",
      "samples_per_second      94.4090  91.6290\n",
      "steps_per_second         2.9500   3.2070\n"
     ]
    }
   ],
   "source": [
    "results_before_train = ner_trainer.evaluate(\n",
    "    eval_dataset={\"train\": tokenized_ner_datasets[\"train\"], \"test\": tokenized_ner_datasets[\"test\"]}\n",
    ")\n",
    "get_pretty_metrics(results_before_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 02:17, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Geopolit</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Media</th>\n",
       "      <th>Org</th>\n",
       "      <th>Per</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.582400</td>\n",
       "      <td>1.500488</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3871}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.118800</td>\n",
       "      <td>1.012015</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3871}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.844265</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3871}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.743800</td>\n",
       "      <td>0.732967</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.1348314606741573, 'recall': 0.14879876001033324, 'f1': 0.1414712022596095, 'number': 3871}</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>0.053912</td>\n",
       "      <td>0.077026</td>\n",
       "      <td>0.796301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.607300</td>\n",
       "      <td>0.687297</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.20512820512820512, 'recall': 0.004509582863585118, 'f1': 0.00882515168229454, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.14482010486349667, 'recall': 0.20692327563936966, 'f1': 0.1703892788768347, 'number': 3871}</td>\n",
       "      <td>0.145659</td>\n",
       "      <td>0.076469</td>\n",
       "      <td>0.100288</td>\n",
       "      <td>0.802745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.673200</td>\n",
       "      <td>0.662424</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.37583892617449666, 'recall': 0.03156708004509583, 'f1': 0.058242329693187725, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.13842281879194632, 'recall': 0.21312322397313355, 'f1': 0.1678364357644187, 'number': 3871}</td>\n",
       "      <td>0.149728</td>\n",
       "      <td>0.087701</td>\n",
       "      <td>0.110613</td>\n",
       "      <td>0.805658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>0.638624</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.3873056994818653, 'recall': 0.0842728297632469, 'f1': 0.13842592592592595, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.13903471634208298, 'recall': 0.21208989925083957, 'f1': 0.16796235679214402, 'number': 3871}</td>\n",
       "      <td>0.167740</td>\n",
       "      <td>0.104830</td>\n",
       "      <td>0.129025</td>\n",
       "      <td>0.812141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.8, 'recall': 0.0072007200720072, 'f1': 0.014272970561998215, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.401536312849162, 'recall': 0.1620631341600902, 'f1': 0.23092369477911648, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.1383399209486166, 'recall': 0.20795660036166366, 'f1': 0.16615067079463366, 'number': 3871}</td>\n",
       "      <td>0.191158</td>\n",
       "      <td>0.129914</td>\n",
       "      <td>0.154695</td>\n",
       "      <td>0.815994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.656800</td>\n",
       "      <td>0.601187</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7678571428571429, 'recall': 0.0387038703870387, 'f1': 0.07369323050556983, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4044554455445545, 'recall': 0.2302705749718151, 'f1': 0.2934626436781609, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.14696370822853036, 'recall': 0.2113149057091191, 'f1': 0.17336017802267667, 'number': 3871}</td>\n",
       "      <td>0.219576</td>\n",
       "      <td>0.157057</td>\n",
       "      <td>0.183128</td>\n",
       "      <td>0.823843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.584500</td>\n",
       "      <td>0.586683</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7692307692307693, 'recall': 0.09000900090009001, 'f1': 0.16116035455278002, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.40730106644790814, 'recall': 0.2798759864712514, 'f1': 0.3317741396592048, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.15407352669499352, 'recall': 0.215448204598295, 'f1': 0.1796639379577768, 'number': 3871}</td>\n",
       "      <td>0.241448</td>\n",
       "      <td>0.180363</td>\n",
       "      <td>0.206483</td>\n",
       "      <td>0.827942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.641200</td>\n",
       "      <td>0.572242</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.8116591928251121, 'recall': 0.1629162916291629, 'f1': 0.27136431784107945, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.39438596491228073, 'recall': 0.31679819616685456, 'f1': 0.35135979993748045, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.15939820986478767, 'recall': 0.2162231981400155, 'f1': 0.18351238763429073, 'number': 3871}</td>\n",
       "      <td>0.257328</td>\n",
       "      <td>0.200487</td>\n",
       "      <td>0.225379</td>\n",
       "      <td>0.832466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.585400</td>\n",
       "      <td>0.556647</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7964601769911505, 'recall': 0.24302430243024303, 'f1': 0.37241379310344824, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4035830618892508, 'recall': 0.3492108229988726, 'f1': 0.3744333635539438, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.1696022165050465, 'recall': 0.22138982175148542, 'f1': 0.1920663379650381, 'number': 3871}</td>\n",
       "      <td>0.279603</td>\n",
       "      <td>0.221453</td>\n",
       "      <td>0.247153</td>\n",
       "      <td>0.837247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.601000</td>\n",
       "      <td>0.544139</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7720090293453724, 'recall': 0.30783078307830786, 'f1': 0.44015444015444016, 'number': 1111}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.0006963788300835655, 'f1': 0.0013917884481558804, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4122137404580153, 'recall': 0.3804960541149944, 'f1': 0.3957203576139528, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.17836078909904413, 'recall': 0.2265564453629553, 'f1': 0.19959035047792442, 'number': 3871}</td>\n",
       "      <td>0.297557</td>\n",
       "      <td>0.240547</td>\n",
       "      <td>0.266032</td>\n",
       "      <td>0.841178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.535368</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7535353535353535, 'recall': 0.3357335733573357, 'f1': 0.4645080946450809, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.5714285714285714, 'recall': 0.002785515320334262, 'f1': 0.005544005544005545, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4106364428945074, 'recall': 0.39825253664036075, 'f1': 0.40434969237373014, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.1798308929676222, 'recall': 0.22526478946008782, 'f1': 0.2, 'number': 3871}</td>\n",
       "      <td>0.302638</td>\n",
       "      <td>0.249158</td>\n",
       "      <td>0.273306</td>\n",
       "      <td>0.842712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.605500</td>\n",
       "      <td>0.524715</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7475915221579962, 'recall': 0.34923492349234925, 'f1': 0.47607361963190187, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.45, 'recall': 0.006267409470752089, 'f1': 0.012362637362637362, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4089651355838406, 'recall': 0.4165727170236753, 'f1': 0.41273387321977106, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.18918345705196182, 'recall': 0.23043141307155773, 'f1': 0.2077801071511763, 'number': 3871}</td>\n",
       "      <td>0.311845</td>\n",
       "      <td>0.258985</td>\n",
       "      <td>0.282968</td>\n",
       "      <td>0.845470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.521708</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7306273062730627, 'recall': 0.3564356435643564, 'f1': 0.4791288566243194, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.4090909090909091, 'recall': 0.006267409470752089, 'f1': 0.012345679012345678, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.3978658536585366, 'recall': 0.4413754227733935, 'f1': 0.41849278460716194, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.18892165122156698, 'recall': 0.2317230689744252, 'f1': 0.20814479638009048, 'number': 3871}</td>\n",
       "      <td>0.309887</td>\n",
       "      <td>0.268439</td>\n",
       "      <td>0.287677</td>\n",
       "      <td>0.845985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>0.515957</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7284172661870504, 'recall': 0.3645364536453645, 'f1': 0.4859028194361128, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.4117647058823529, 'recall': 0.009749303621169917, 'f1': 0.019047619047619046, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.1111111111111111, 'recall': 0.001392757660167131, 'f1': 0.002751031636863824, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4062906160644658, 'recall': 0.44052987598647125, 'f1': 0.4227180527383368, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.19231585650604968, 'recall': 0.23404804959958667, 'f1': 0.21113959450011652, 'number': 3871}</td>\n",
       "      <td>0.315496</td>\n",
       "      <td>0.270404</td>\n",
       "      <td>0.291215</td>\n",
       "      <td>0.846913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.568500</td>\n",
       "      <td>0.511806</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7229129662522202, 'recall': 0.36633663366336633, 'f1': 0.48626045400238943, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.44680851063829785, 'recall': 0.014623955431754874, 'f1': 0.028320971004720162, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.1111111111111111, 'recall': 0.001392757660167131, 'f1': 0.002751031636863824, 'number': 718}</td>\n",
       "      <td>{'precision': 0.40341622707862346, 'recall': 0.45264937993235627, 'f1': 0.4266170806215965, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.19810303944815694, 'recall': 0.2374063549470421, 'f1': 0.21598119858989426, 'number': 3871}</td>\n",
       "      <td>0.319732</td>\n",
       "      <td>0.276488</td>\n",
       "      <td>0.296542</td>\n",
       "      <td>0.848254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>0.508943</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7105719237435009, 'recall': 0.369036903690369, 'f1': 0.4857819905213271, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.43636363636363634, 'recall': 0.016713091922005572, 'f1': 0.03219315895372234, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.1, 'recall': 0.001392757660167131, 'f1': 0.002747252747252747, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4028085735402809, 'recall': 0.4608229988726043, 'f1': 0.4298672275535691, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.20222756060275168, 'recall': 0.23921467321105658, 'f1': 0.2191715976331361, 'number': 3871}</td>\n",
       "      <td>0.322845</td>\n",
       "      <td>0.280419</td>\n",
       "      <td>0.300140</td>\n",
       "      <td>0.849130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.529700</td>\n",
       "      <td>0.508739</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>{'precision': 0.7110726643598616, 'recall': 0.36993699369936994, 'f1': 0.48667850799289525, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.42592592592592593, 'recall': 0.016016713091922007, 'f1': 0.030872483221476513, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.1, 'recall': 0.001392757660167131, 'f1': 0.002747252747252747, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4035740878629933, 'recall': 0.45828635851183763, 'f1': 0.4291936122475914, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.20082770638205183, 'recall': 0.2381813484887626, 'f1': 0.21791538643346725, 'number': 3871}</td>\n",
       "      <td>0.322069</td>\n",
       "      <td>0.279203</td>\n",
       "      <td>0.299108</td>\n",
       "      <td>0.848988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.7400375214219094, metrics={'train_runtime': 138.2674, 'train_samples_per_second': 115.718, 'train_steps_per_second': 3.616, 'total_flos': 113325785088000.0, 'train_loss': 0.7400375214219094, 'epoch': 20.0})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Метрики по сущностям (Train) ===\n",
      "          precision  recall      f1   number\n",
      "GEOPOLIT     0.7568  0.3784  0.5045   4736.0\n",
      "LOC          0.3930  0.0157  0.0302   6440.0\n",
      "MEDIA        0.0781  0.0018  0.0036   2708.0\n",
      "ORG          0.3908  0.4519  0.4192  13890.0\n",
      "PER          0.2067  0.2449  0.2242  15204.0\n",
      "\n",
      "=== Метрики по сущностям (Test) ===\n",
      "          precision  recall      f1  number\n",
      "GEOPOLIT     0.7111  0.3699  0.4867  1111.0\n",
      "LOC          0.4259  0.0160  0.0309  1436.0\n",
      "MEDIA        0.1000  0.0014  0.0027   718.0\n",
      "ORG          0.4036  0.4583  0.4292  3548.0\n",
      "PER          0.2008  0.2382  0.2179  3871.0\n",
      "\n",
      "=== Общие метрики ===\n",
      "                           Train      Test\n",
      "loss                      0.4981    0.5087\n",
      "model_preparation_time    0.0007    0.0007\n",
      "overall_precision         0.3236    0.3221\n",
      "overall_recall            0.2769    0.2792\n",
      "overall_f1                0.2984    0.2991\n",
      "overall_accuracy          0.8499    0.8490\n",
      "runtime                   4.7113    1.3897\n",
      "samples_per_second      169.8030  143.9160\n",
      "steps_per_second          5.3060    5.0370\n"
     ]
    }
   ],
   "source": [
    "# очевидно, метрики после обучения заметно выросли\n",
    "results_after_train = ner_trainer.evaluate(\n",
    "    eval_dataset={\"train\": tokenized_ner_datasets[\"train\"], \"test\": tokenized_ner_datasets[\"test\"]}\n",
    ")\n",
    "get_pretty_metrics(results_after_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_trainer.save_model(\"./ner_rubert_pretrained_20epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Дообучение в MLM режиме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = ner_tokenizer.model_max_length  # 512\n",
    "\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)] for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63086500647a47479aafc939904726c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 2264, 548, 14492, 15712, 329, 5677, 1941, 11401, 10138, 26609, 7410, 705, 23280, 2056, 4108, 1903, 3125, 283, 4829, 2448, 25724, 2259, 1090, 2264, 301, 24340, 1690, 290, 5952, 7603, 548, 14492, 15605, 25933, 1172, 7305, 26609, 7410, 283, 4829, 1987, 28622, 15585, 17960, 705, 23280, 2056, 4108, 1903, 3125, 2083, 10440, 16, 1154, 10658, 16282, 314, 650, 16196, 10516, 16, 4495, 3277, 15764, 2058, 548, 12865, 28037, 25943, 16615, 21455, 7970, 314, 10138, 761, 2014, 719, 3423, 18, 14658, 16, 25933, 15462, 1241, 16, 22903, 815, 1556, 13678, 2804, 751, 15803, 26947, 283, 4829, 1987, 28622, 15585, 17960, 705, 23280, 2056, 4108, 1903, 3125, 314, 11652, 320, 285, 19825, 9131, 300, 4222, 753, 14892, 15144, 751, 12, 8419, 1982, 5153, 5387, 653, 13, 18, 294, 7727, 13783, 22587, 1668, 14892, 15144, 751, 320, 1464, 21568, 19173, 5204, 10863, 15905, 16, 10485, 12757, 644, 650, 21385, 16, 6744, 6, 328, 626, 3782, 16777, 331, 26191, 775, 21179, 2264, 705, 314, 2702, 28719, 10130, 5313, 2686, 329, 2056, 4108, 1903, 3125, 3882, 9311, 761, 6, 18, 3130, 5058, 314, 283, 4829, 1987, 28622, 15585, 8945, 626, 14892, 15144, 751, 16, 331, 3074, 7322, 872, 18875, 16, 1480, 25219, 761, 6062, 15016, 13376, 320, 17746, 5750, 12105, 22850, 6331, 329, 2056, 4108, 1903, 3125, 3882, 9311, 761, 16, 312, 1479, 20147, 864, 341, 5179, 14795, 14410, 6467, 18, 282, 802, 17, 333, 3417, 2904, 13858, 603, 314, 280, 27631, 5198, 19451, 7907, 12, 1219, 9172, 13, 18, 3, 2, 282, 290, 19661, 19560, 948, 17, 27610, 9772, 7176, 548, 14492, 15712, 7049, 28178, 14892, 20338, 9290, 290, 19661, 19560, 948, 17, 27610, 9772, 7176, 548, 14492, 14020, 320, 18, 326, 18, 14934, 17, 28178, 18065, 283, 25800, 3414, 548, 10513, 16597, 13594, 16636, 18, 282, 987, 20413, 26903, 626, 650, 2448, 16991, 16, 548, 6205, 650, 283, 25800, 3414, 2225, 24505, 26188, 1044, 7274, 5054, 12372, 948, 16, 24516, 637, 3553, 16, 1154, 10658, 13325, 288, 5905, 19195, 17, 298, 4292, 28169, 18, 290, 8774, 14009, 14721, 283, 25800, 3414, 19849, 644, 20399, 8648, 290, 5165, 4845, 280, 14548, 1139, 290, 6101, 2412, 16, 2371, 23, 3553, 733, 22575, 12737, 314, 22223, 19150, 17189, 22902, 23019, 5980, 764, 8503, 292, 1813, 18520, 1841, 18, 7644, 4427, 8621, 8648, 2514, 25335, 13002, 869, 5624, 16, 1046, 15273, 769, 22797, 23964, 23485, 650, 2514, 10763, 13854, 23552, 314, 328, 4608, 11357, 18814, 10660, 16, 1154, 10658, 13325, 6, 17797, 12376, 6, 18, 5596, 290, 6101, 2412, 733, 22970, 16, 1046, 9886, 23019, 5980, 751, 14791, 811, 10789, 6744, 8281, 314, 25660, 331, 28057, 1348, 11143, 329, 324, 20879, 1987, 1845, 8506, 320, 17016, 329, 328, 5041, 2987, 14207, 1635, 341, 5179, 14795, 14410, 28674, 16, 733, 26375, 21220, 1478, 1537, 21634, 18, 13588, 14922, 25549, 283, 25800, 3414, 19849, 644, 16, 290, 6101, 2412, 1464, 24902, 29179, 16, 1046, 1218, 6, 329, 3649, 314, 2663, 1154, 25302, 20645, 314, 4449, 14934, 17, 28178, 290, 19661, 19560, 948, 17, 27610, 9772, 7176, 6, 18, 5596, 8648, 16191, 16, 1046, 283, 25800, 1813, 14480, 314, 328, 4608], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2, 2264, 548, 14492, 15712, 329, 5677, 1941, 11401, 10138, 26609, 7410, 705, 23280, 2056, 4108, 1903, 3125, 283, 4829, 2448, 25724, 2259, 1090, 2264, 301, 24340, 1690, 290, 5952, 7603, 548, 14492, 15605, 25933, 1172, 7305, 26609, 7410, 283, 4829, 1987, 28622, 15585, 17960, 705, 23280, 2056, 4108, 1903, 3125, 2083, 10440, 16, 1154, 10658, 16282, 314, 650, 16196, 10516, 16, 4495, 3277, 15764, 2058, 548, 12865, 28037, 25943, 16615, 21455, 7970, 314, 10138, 761, 2014, 719, 3423, 18, 14658, 16, 25933, 15462, 1241, 16, 22903, 815, 1556, 13678, 2804, 751, 15803, 26947, 283, 4829, 1987, 28622, 15585, 17960, 705, 23280, 2056, 4108, 1903, 3125, 314, 11652, 320, 285, 19825, 9131, 300, 4222, 753, 14892, 15144, 751, 12, 8419, 1982, 5153, 5387, 653, 13, 18, 294, 7727, 13783, 22587, 1668, 14892, 15144, 751, 320, 1464, 21568, 19173, 5204, 10863, 15905, 16, 10485, 12757, 644, 650, 21385, 16, 6744, 6, 328, 626, 3782, 16777, 331, 26191, 775, 21179, 2264, 705, 314, 2702, 28719, 10130, 5313, 2686, 329, 2056, 4108, 1903, 3125, 3882, 9311, 761, 6, 18, 3130, 5058, 314, 283, 4829, 1987, 28622, 15585, 8945, 626, 14892, 15144, 751, 16, 331, 3074, 7322, 872, 18875, 16, 1480, 25219, 761, 6062, 15016, 13376, 320, 17746, 5750, 12105, 22850, 6331, 329, 2056, 4108, 1903, 3125, 3882, 9311, 761, 16, 312, 1479, 20147, 864, 341, 5179, 14795, 14410, 6467, 18, 282, 802, 17, 333, 3417, 2904, 13858, 603, 314, 280, 27631, 5198, 19451, 7907, 12, 1219, 9172, 13, 18, 3, 2, 282, 290, 19661, 19560, 948, 17, 27610, 9772, 7176, 548, 14492, 15712, 7049, 28178, 14892, 20338, 9290, 290, 19661, 19560, 948, 17, 27610, 9772, 7176, 548, 14492, 14020, 320, 18, 326, 18, 14934, 17, 28178, 18065, 283, 25800, 3414, 548, 10513, 16597, 13594, 16636, 18, 282, 987, 20413, 26903, 626, 650, 2448, 16991, 16, 548, 6205, 650, 283, 25800, 3414, 2225, 24505, 26188, 1044, 7274, 5054, 12372, 948, 16, 24516, 637, 3553, 16, 1154, 10658, 13325, 288, 5905, 19195, 17, 298, 4292, 28169, 18, 290, 8774, 14009, 14721, 283, 25800, 3414, 19849, 644, 20399, 8648, 290, 5165, 4845, 280, 14548, 1139, 290, 6101, 2412, 16, 2371, 23, 3553, 733, 22575, 12737, 314, 22223, 19150, 17189, 22902, 23019, 5980, 764, 8503, 292, 1813, 18520, 1841, 18, 7644, 4427, 8621, 8648, 2514, 25335, 13002, 869, 5624, 16, 1046, 15273, 769, 22797, 23964, 23485, 650, 2514, 10763, 13854, 23552, 314, 328, 4608, 11357, 18814, 10660, 16, 1154, 10658, 13325, 6, 17797, 12376, 6, 18, 5596, 290, 6101, 2412, 733, 22970, 16, 1046, 9886, 23019, 5980, 751, 14791, 811, 10789, 6744, 8281, 314, 25660, 331, 28057, 1348, 11143, 329, 324, 20879, 1987, 1845, 8506, 320, 17016, 329, 328, 5041, 2987, 14207, 1635, 341, 5179, 14795, 14410, 28674, 16, 733, 26375, 21220, 1478, 1537, 21634, 18, 13588, 14922, 25549, 283, 25800, 3414, 19849, 644, 16, 290, 6101, 2412, 1464, 24902, 29179, 16, 1046, 1218, 6, 329, 3649, 314, 2663, 1154, 25302, 20645, 314, 4449, 14934, 17, 28178, 290, 19661, 19560, 948, 17, 27610, 9772, 7176, 6, 18, 5596, 8648, 16191, 16, 1046, 283, 25800, 1813, 14480, 314, 328, 4608]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_mlm_dataset = (\n",
    "    tokenized_ner_datasets[\"train\"]\n",
    "    .remove_columns(\n",
    "        [\n",
    "            col\n",
    "            for col in tokenized_ner_datasets[\"train\"].column_names\n",
    "            if col not in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]\n",
    "        ]\n",
    "    )\n",
    "    .map(group_texts, batched=True)\n",
    ")\n",
    "print(tokenized_mlm_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаю новый идентичный токенайзер, чтобы не затронуть изменениями старый\n",
    "mlm_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# trainer выдает ошибку, если так делать, кажется, что это не важно,\n",
    "# так как мы выше дополнили все последовательности до максимальной длины\n",
    "# mlm_tokenizer.pad_token = mlm_tokenizer.eos_token\n",
    "mlm_data_collator = DataCollatorForLanguageModeling(tokenizer=mlm_tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_model = AutoModelForMaskedLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# большинство аргументов с пары, не вижу смысла их обосновывать\n",
    "mlm_args = TrainingArguments(\n",
    "    output_dir=\"mlm\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=40,  # сначала взяла количество эпох как в ner, но качество увеличилось на 1-3%, поэтому увеличила до 40\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    run_name=\"mlm\",\n",
    "    logging_steps=1,\n",
    ")\n",
    "\n",
    "mlm_trainer = Trainer(\n",
    "    model=mlm_model,\n",
    "    args=mlm_args,\n",
    "    train_dataset=tokenized_mlm_dataset,\n",
    "    eval_dataset=tokenized_mlm_dataset,\n",
    "    processing_class=mlm_tokenizer,\n",
    "    data_collator=mlm_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def compute_perplexity(loss):\n",
    "    return math.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 01:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  455.2356864784544\n",
      "{'eval_loss': 6.120815277099609, 'eval_model_preparation_time': 0.0019, 'eval_runtime': 5.1286, 'eval_samples_per_second': 117.967, 'eval_steps_per_second': 3.705}\n"
     ]
    }
   ],
   "source": [
    "res_mlm_before_training = mlm_trainer.evaluate(tokenized_mlm_dataset)\n",
    "print(\"Perplexity: \", compute_perplexity(res_mlm_before_training[\"eval_loss\"]))\n",
    "print(res_mlm_before_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='760' max='760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [760/760 42:21, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.909500</td>\n",
       "      <td>5.571387</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.697100</td>\n",
       "      <td>5.414328</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.587100</td>\n",
       "      <td>5.320981</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.500900</td>\n",
       "      <td>5.250452</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.328000</td>\n",
       "      <td>5.183411</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.424400</td>\n",
       "      <td>5.145228</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.335300</td>\n",
       "      <td>5.052497</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.357600</td>\n",
       "      <td>5.050497</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.197100</td>\n",
       "      <td>4.955825</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.370600</td>\n",
       "      <td>4.893347</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>5.340600</td>\n",
       "      <td>4.857085</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.271200</td>\n",
       "      <td>4.787170</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.291000</td>\n",
       "      <td>4.745839</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.168700</td>\n",
       "      <td>4.705161</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5.028100</td>\n",
       "      <td>4.627157</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.105800</td>\n",
       "      <td>4.570446</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.136300</td>\n",
       "      <td>4.555082</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.992700</td>\n",
       "      <td>4.532973</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.003300</td>\n",
       "      <td>4.480891</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.024600</td>\n",
       "      <td>4.426948</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>4.919900</td>\n",
       "      <td>4.376157</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>4.910700</td>\n",
       "      <td>4.366586</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>4.827500</td>\n",
       "      <td>4.322978</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>4.903400</td>\n",
       "      <td>4.278388</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>4.915500</td>\n",
       "      <td>4.300489</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>4.949800</td>\n",
       "      <td>4.245904</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>4.791600</td>\n",
       "      <td>4.220967</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>4.841200</td>\n",
       "      <td>4.226049</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>4.789500</td>\n",
       "      <td>4.170284</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.710900</td>\n",
       "      <td>4.184309</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>4.760100</td>\n",
       "      <td>4.161290</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>4.767600</td>\n",
       "      <td>4.147514</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>4.695300</td>\n",
       "      <td>4.123413</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>4.641000</td>\n",
       "      <td>4.136858</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>4.641800</td>\n",
       "      <td>4.108016</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>4.810800</td>\n",
       "      <td>4.097974</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>4.784500</td>\n",
       "      <td>4.102987</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>4.733300</td>\n",
       "      <td>4.094676</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>4.733000</td>\n",
       "      <td>4.114580</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.725700</td>\n",
       "      <td>4.089816</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=760, training_loss=5.052213277942256, metrics={'train_runtime': 2545.1215, 'train_samples_per_second': 9.508, 'train_steps_per_second': 0.299, 'total_flos': 180653518848000.0, 'train_loss': 5.052213277942256, 'epoch': 40.0})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  59.61179348144589\n",
      "{'eval_loss': 4.08785343170166, 'eval_model_preparation_time': 0.0019, 'eval_runtime': 2.7605, 'eval_samples_per_second': 219.166, 'eval_steps_per_second': 6.883, 'epoch': 40.0}\n"
     ]
    }
   ],
   "source": [
    "res_mlm_after_training = mlm_trainer.evaluate(tokenized_mlm_dataset)\n",
    "print(\"Perplexity: \", compute_perplexity(res_mlm_after_training[\"eval_loss\"]))\n",
    "print(res_mlm_after_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_trainer.save_model(\"./mlm_rubert_pretrained_10epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ./mlm_rubert_pretrained_10epochs and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_mlm_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"./mlm_rubert_pretrained_10epochs\", num_labels=len(label_list)\n",
    ")\n",
    "pretrained_mlm_model.config.id2label = dict(enumerate(label_list))\n",
    "pretrained_mlm_model.config.label2id = {v: k for k, v in pretrained_mlm_model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_after_mlm_trainer = Trainer(\n",
    "    model=pretrained_mlm_model,\n",
    "    args=ner_args,\n",
    "    train_dataset=tokenized_ner_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_ner_datasets[\"test\"],\n",
    "    processing_class=ner_tokenizer,\n",
    "    data_collator=ner_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Метрики по сущностям (Train) ===\n",
      "          precision  recall      f1   number\n",
      "GEOPOLIT     0.0092  0.0714  0.0163   4736.0\n",
      "LOC          0.0090  0.0697  0.0160   6440.0\n",
      "MEDIA        0.0032  0.0569  0.0060   2708.0\n",
      "ORG          0.0758  0.1289  0.0955  13890.0\n",
      "PER          0.0274  0.1000  0.0430  15204.0\n",
      "\n",
      "=== Метрики по сущностям (Test) ===\n",
      "          precision  recall      f1  number\n",
      "GEOPOLIT     0.0079  0.0675  0.0141  1111.0\n",
      "LOC          0.0096  0.0808  0.0171  1436.0\n",
      "MEDIA        0.0031  0.0529  0.0058   718.0\n",
      "ORG          0.0889  0.1502  0.1117  3548.0\n",
      "PER          0.0284  0.1018  0.0444  3871.0\n",
      "\n",
      "=== Общие метрики ===\n",
      "                           Train      Test\n",
      "loss                      2.3707    2.3723\n",
      "model_preparation_time    0.0033    0.0033\n",
      "overall_precision         0.0199    0.0214\n",
      "overall_recall            0.0989    0.1082\n",
      "overall_f1                0.0331    0.0358\n",
      "overall_accuracy          0.1292    0.1276\n",
      "runtime                   5.9062    1.8114\n",
      "samples_per_second      135.4520  110.4130\n",
      "steps_per_second          4.2330    3.8640\n"
     ]
    }
   ],
   "source": [
    "results_before_train_with_mlm = ner_after_mlm_trainer.evaluate(\n",
    "    eval_dataset={\"train\": tokenized_ner_datasets[\"train\"], \"test\": tokenized_ner_datasets[\"test\"]}\n",
    ")\n",
    "get_pretty_metrics(results_before_train_with_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 02:31, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Geopolit</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Media</th>\n",
       "      <th>Org</th>\n",
       "      <th>Per</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.423700</td>\n",
       "      <td>1.347741</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3871}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.080800</td>\n",
       "      <td>0.971807</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3871}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.831700</td>\n",
       "      <td>0.819301</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.0002583311805734952, 'f1': 0.0005165289256198347, 'number': 3871}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.759621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.711500</td>\n",
       "      <td>0.698571</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.6698113207547169, 'recall': 0.06003382187147689, 'f1': 0.11019141231246768, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.10920897284533648, 'recall': 0.09558253681219323, 'f1': 0.1019424163107866, 'number': 3871}</td>\n",
       "      <td>0.157312</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.798750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>0.641456</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.5784132841328413, 'recall': 0.17671927846674182, 'f1': 0.2707253886010363, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.14769926047658175, 'recall': 0.18574011883234307, 'f1': 0.1645497196475569, 'number': 3871}</td>\n",
       "      <td>0.226142</td>\n",
       "      <td>0.125983</td>\n",
       "      <td>0.161818</td>\n",
       "      <td>0.814937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.622300</td>\n",
       "      <td>0.602785</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.49226361031518623, 'recall': 0.24210822998872605, 'f1': 0.3245796334781787, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.16030056355666875, 'recall': 0.19839834668044434, 'f1': 0.17732625259755253, 'number': 3871}</td>\n",
       "      <td>0.248853</td>\n",
       "      <td>0.152284</td>\n",
       "      <td>0.188944</td>\n",
       "      <td>0.823160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.573813</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.0009000900090009, 'f1': 0.0017985611510791368, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.450313339301701, 'recall': 0.2835400225479143, 'f1': 0.34797647872708404, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.16344969199178644, 'recall': 0.2056316197365022, 'f1': 0.1821301910536552, 'number': 3871}</td>\n",
       "      <td>0.253515</td>\n",
       "      <td>0.168757</td>\n",
       "      <td>0.202630</td>\n",
       "      <td>0.828857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>0.551950</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.9130434782608695, 'recall': 0.018901890189018902, 'f1': 0.03703703703703704, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.42121630960608153, 'recall': 0.3435738444193912, 'f1': 0.3784538963054952, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.17114093959731544, 'recall': 0.2107982433479721, 'f1': 0.1889107535594398, 'number': 3871}</td>\n",
       "      <td>0.266770</td>\n",
       "      <td>0.192437</td>\n",
       "      <td>0.223588</td>\n",
       "      <td>0.834257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.584100</td>\n",
       "      <td>0.528616</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.9375, 'recall': 0.09450945094509451, 'f1': 0.17170891251022077, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.058823529411764705, 'recall': 0.001392757660167131, 'f1': 0.0027210884353741495, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4176100628930818, 'recall': 0.3742953776775648, 'f1': 0.3947681331747919, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.18112798264642083, 'recall': 0.2157065357788685, 'f1': 0.19691074165782338, 'number': 3871}</td>\n",
       "      <td>0.286038</td>\n",
       "      <td>0.212467</td>\n",
       "      <td>0.243824</td>\n",
       "      <td>0.839954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>0.510254</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.8814229249011858, 'recall': 0.2007200720072007, 'f1': 0.3269794721407625, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.03125, 'recall': 0.001392757660167131, 'f1': 0.0026666666666666666, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.41946403385049363, 'recall': 0.41910935738444194, 'f1': 0.41928662061187083, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.1919873959036687, 'recall': 0.2203564970291914, 'f1': 0.20519605484724562, 'number': 3871}</td>\n",
       "      <td>0.308850</td>\n",
       "      <td>0.240079</td>\n",
       "      <td>0.270156</td>\n",
       "      <td>0.845560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.574100</td>\n",
       "      <td>0.494897</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.8630573248407644, 'recall': 0.24392439243924394, 'f1': 0.3803508771929825, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.037037037037037035, 'recall': 0.0020891364902506965, 'f1': 0.003955174686882004, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4140342416204485, 'recall': 0.483934611048478, 'f1': 0.44626380766731644, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.2029224605232147, 'recall': 0.2224231464737794, 'f1': 0.2122257825979788, 'number': 3871}</td>\n",
       "      <td>0.324644</td>\n",
       "      <td>0.266941</td>\n",
       "      <td>0.292979</td>\n",
       "      <td>0.850535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.479201</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.8106060606060606, 'recall': 0.2889288928892889, 'f1': 0.4260119442601194, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0707070707070707, 'recall': 0.004874651810584958, 'f1': 0.009120521172638438, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4225960445555808, 'recall': 0.5239571589627959, 'f1': 0.4678495029570907, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.21428571428571427, 'recall': 0.22784810126582278, 'f1': 0.22085889570552145, 'number': 3871}</td>\n",
       "      <td>0.340622</td>\n",
       "      <td>0.287252</td>\n",
       "      <td>0.311669</td>\n",
       "      <td>0.855767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>0.468231</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.7711111111111111, 'recall': 0.31233123312331235, 'f1': 0.444586803331198, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.12142857142857143, 'recall': 0.011838440111420613, 'f1': 0.021573604060913704, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.43277216610549946, 'recall': 0.5434047350620068, 'f1': 0.4818193177558416, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.2228515144053189, 'recall': 0.23378971841901316, 'f1': 0.2281896116994453, 'number': 3871}</td>\n",
       "      <td>0.351087</td>\n",
       "      <td>0.299232</td>\n",
       "      <td>0.323092</td>\n",
       "      <td>0.858822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.491500</td>\n",
       "      <td>0.458664</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.7577639751552795, 'recall': 0.32943294329432943, 'f1': 0.45922208281053956, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.19101123595505617, 'recall': 0.023676880222841225, 'f1': 0.042131350681536554, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4329608938547486, 'recall': 0.5679255918827508, 'f1': 0.4913435747378688, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.23196138211382114, 'recall': 0.23585636786360115, 'f1': 0.2338926604329448, 'number': 3871}</td>\n",
       "      <td>0.359745</td>\n",
       "      <td>0.311494</td>\n",
       "      <td>0.333885</td>\n",
       "      <td>0.861374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>0.450468</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.7470588235294118, 'recall': 0.34293429342934295, 'f1': 0.4700801974090068, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.19230769230769232, 'recall': 0.027855153203342618, 'f1': 0.048661800486618, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.43458933107535985, 'recall': 0.5786358511837655, 'f1': 0.49637330754352027, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.2422772529997447, 'recall': 0.24515629036424696, 'f1': 0.24370826913199792, 'number': 3871}</td>\n",
       "      <td>0.365744</td>\n",
       "      <td>0.320386</td>\n",
       "      <td>0.341566</td>\n",
       "      <td>0.863616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.447561</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.7429643527204502, 'recall': 0.3564356435643564, 'f1': 0.48175182481751827, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.21397379912663755, 'recall': 0.034122562674094706, 'f1': 0.05885885885885886, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4304635761589404, 'recall': 0.60456595264938, 'f1': 0.5028718790294221, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.24610671432218534, 'recall': 0.2490312580728494, 'f1': 0.2475603492552645, 'number': 3871}</td>\n",
       "      <td>0.367833</td>\n",
       "      <td>0.332647</td>\n",
       "      <td>0.349356</td>\n",
       "      <td>0.864570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.441493</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.7395264116575592, 'recall': 0.36543654365436545, 'f1': 0.4891566265060241, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.2384937238493724, 'recall': 0.03969359331476323, 'f1': 0.0680597014925373, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.43580322514798936, 'recall': 0.6017474633596392, 'f1': 0.5055049129868592, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.25227568270481143, 'recall': 0.2505812451562904, 'f1': 0.2514256091238984, 'number': 3871}</td>\n",
       "      <td>0.374318</td>\n",
       "      <td>0.333957</td>\n",
       "      <td>0.352988</td>\n",
       "      <td>0.865988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.438135</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.7344028520499108, 'recall': 0.3708370837083708, 'f1': 0.4928229665071771, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.2627450980392157, 'recall': 0.04665738161559889, 'f1': 0.07924305144884684, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.43294257897874033, 'recall': 0.6141488162344984, 'f1': 0.5078662160587345, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.2569626904887021, 'recall': 0.25264789460087833, 'f1': 0.25478702618210236, 'number': 3871}</td>\n",
       "      <td>0.376592</td>\n",
       "      <td>0.340322</td>\n",
       "      <td>0.357540</td>\n",
       "      <td>0.867238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.436321</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.7323943661971831, 'recall': 0.37443744374437443, 'f1': 0.4955330553901132, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.26666666666666666, 'recall': 0.05013927576601671, 'f1': 0.08440797186400938, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4362942122186495, 'recall': 0.6118940248027057, 'f1': 0.50938526513374, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.25824320759694014, 'recall': 0.25290622578145183, 'f1': 0.25554685460715226, 'number': 3871}</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.340509</td>\n",
       "      <td>0.358618</td>\n",
       "      <td>0.867689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.466000</td>\n",
       "      <td>0.435977</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>{'precision': 0.7306338028169014, 'recall': 0.37353735373537356, 'f1': 0.49434187016081, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.26373626373626374, 'recall': 0.05013927576601671, 'f1': 0.0842598010532475, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4364295788837397, 'recall': 0.6104847801578354, 'f1': 0.5089883679943602, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.2596991290577989, 'recall': 0.2541978816843193, 'f1': 0.2569190600522194, 'number': 3871}</td>\n",
       "      <td>0.379131</td>\n",
       "      <td>0.340416</td>\n",
       "      <td>0.358732</td>\n",
       "      <td>0.867638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.6745146901607514, metrics={'train_runtime': 151.544, 'train_samples_per_second': 105.58, 'train_steps_per_second': 3.299, 'total_flos': 113325785088000.0, 'train_loss': 0.6745146901607514, 'epoch': 20.0})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_after_mlm_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Метрики по сущностям (Train) ===\n",
      "          precision  recall      f1   number\n",
      "GEOPOLIT     0.7902  0.3818  0.5148   4736.0\n",
      "LOC          0.3143  0.0668  0.1101   6440.0\n",
      "MEDIA        0.6667  0.0007  0.0015   2708.0\n",
      "ORG          0.4306  0.5987  0.5009  13890.0\n",
      "PER          0.2820  0.2776  0.2798  15204.0\n",
      "\n",
      "=== Метрики по сущностям (Test) ===\n",
      "          precision  recall      f1  number\n",
      "GEOPOLIT     0.7306  0.3735  0.4943  1111.0\n",
      "LOC          0.2637  0.0501  0.0843  1436.0\n",
      "MEDIA        0.0000  0.0000  0.0000   718.0\n",
      "ORG          0.4364  0.6105  0.5090  3548.0\n",
      "PER          0.2597  0.2542  0.2569  3871.0\n",
      "\n",
      "=== Общие метрики ===\n",
      "                           Train      Test\n",
      "loss                      0.4197    0.4360\n",
      "model_preparation_time    0.0033    0.0033\n",
      "overall_precision         0.3895    0.3791\n",
      "overall_recall            0.3438    0.3404\n",
      "overall_f1                0.3652    0.3587\n",
      "overall_accuracy          0.8703    0.8676\n",
      "runtime                   4.7868    1.6656\n",
      "samples_per_second      167.1280  120.0750\n",
      "steps_per_second          5.2230    4.2030\n"
     ]
    }
   ],
   "source": [
    "results_after_train_with_mlm = ner_after_mlm_trainer.evaluate(\n",
    "    eval_dataset={\"train\": tokenized_ner_datasets[\"train\"], \"test\": tokenized_ner_datasets[\"test\"]}\n",
    ")\n",
    "get_pretty_metrics(results_after_train_with_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_after_mlm_trainer.save_model(\"ner_after_mlm_rubert_pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Использование синтетической разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/ner/Collection5/\"\n",
    "corpus = list(load_ne5(DATA_PATH))\n",
    "ner_data = [extract_labels(item) for item in corpus]\n",
    "ner_train, ner_test = train_test_split(ner_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10831, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Вице, -, премьер, по, социальным, вопросам, Т...</td>\n",
       "      <td>[O, O, O, O, O, O, B-PER, I-PER, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Австрийские, правоохранительные, органы, не, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Сотрудники, социальной, сети, Instagram, проа...</td>\n",
       "      <td>[O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[С, начала, расследования, российского, вмешат...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Хакерская, группировка, Anonymous, опубликова...</td>\n",
       "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O, B-ORG, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Вице, -, премьер, по, социальным, вопросам, Т...   \n",
       "1  [Австрийские, правоохранительные, органы, не, ...   \n",
       "2  [Сотрудники, социальной, сети, Instagram, проа...   \n",
       "3  [С, начала, расследования, российского, вмешат...   \n",
       "4  [Хакерская, группировка, Anonymous, опубликова...   \n",
       "\n",
       "                                                tags  \n",
       "0  [O, O, O, O, O, O, B-PER, I-PER, O, O, O, O, O...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O,...  \n",
       "3  [O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O,...  \n",
       "4  [O, O, B-ORG, O, O, O, O, O, O, O, O, B-ORG, I...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# см. ноутбук hw_4_data_labeling_deeppavlov.ipynb, где была произведена разметка\n",
    "sinthethic_data = pd.read_parquet(\"data/ner/labeled_data.parquet\").rename(\n",
    "    columns={\"list_of_words\": \"tokens\", \"list_of_tags\": \"tags\"}\n",
    ")\n",
    "print(sinthethic_data.shape)\n",
    "sinthethic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11631"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_train.extend(sinthethic_data.to_dict(orient=\"records\"))\n",
    "len(ner_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# все то же самое, что и в пункте 1.\n",
    "ner_data = DatasetDict(\n",
    "    {\"train\": Dataset.from_pandas(pd.DataFrame(ner_train)), \"test\": Dataset.from_pandas(pd.DataFrame(ner_test))}\n",
    ")\n",
    "MODEL_NAME = \"cointegrated/rubert-tiny\"\n",
    "ner_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenized_ner_datasets = ner_data.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(label_list))\n",
    "ner_model.config.id2label = dict(enumerate(label_list))\n",
    "ner_model.config.label2id = {v: k for k, v in ner_model.config.id2label.items()}\n",
    "\n",
    "ner_data_collator = DataCollatorForTokenClassification(ner_tokenizer)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "ner_args = TrainingArguments(\n",
    "    output_dir=\"ner\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    run_name=\"ner\",\n",
    "    logging_steps=1,\n",
    ")\n",
    "\n",
    "ner_trainer = Trainer(\n",
    "    model=ner_model,\n",
    "    args=ner_args,\n",
    "    train_dataset=tokenized_ner_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_ner_datasets[\"test\"],\n",
    "    processing_class=ner_tokenizer,\n",
    "    data_collator=ner_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Метрики по сущностям (Train) ===\n",
      "          precision  recall      f1   number\n",
      "GEOPOLIT     0.0079  0.0338  0.0128   4736.0\n",
      "LOC          0.0105  0.0713  0.0182   6440.0\n",
      "MEDIA        0.0034  0.0602  0.0065   2708.0\n",
      "ORG          0.0472  0.2346  0.0786  13890.0\n",
      "PER          0.0348  0.1832  0.0585  15204.0\n",
      "\n",
      "=== Метрики по сущностям (Test) ===\n",
      "          precision  recall      f1  number\n",
      "GEOPOLIT     0.0062  0.0279  0.0101  1111.0\n",
      "LOC          0.0099  0.0738  0.0175  1436.0\n",
      "MEDIA        0.0034  0.0571  0.0064   718.0\n",
      "ORG          0.0478  0.2255  0.0789  3548.0\n",
      "PER          0.0361  0.1940  0.0609  3871.0\n",
      "\n",
      "=== Общие метрики ===\n",
      "                           Train     Test\n",
      "loss                      2.5079   2.5070\n",
      "model_preparation_time    0.0000   0.0000\n",
      "overall_precision         0.0262   0.0265\n",
      "overall_recall            0.1588   0.1618\n",
      "overall_f1                0.0450   0.0455\n",
      "overall_accuracy          0.0673   0.0673\n",
      "runtime                   7.6980   2.3072\n",
      "samples_per_second      103.9230  86.6870\n",
      "steps_per_second          3.2480   3.0340\n"
     ]
    }
   ],
   "source": [
    "results_before_train = ner_trainer.evaluate(\n",
    "    eval_dataset={\"train\": tokenized_ner_datasets[\"train\"], \"test\": tokenized_ner_datasets[\"test\"]}\n",
    ")\n",
    "get_pretty_metrics(results_before_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 03:11, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Geopolit</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Media</th>\n",
       "      <th>Org</th>\n",
       "      <th>Per</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.448300</td>\n",
       "      <td>1.354650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.15789473684210525, 'recall': 0.0008455467869222097, 'f1': 0.001682085786375105, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.12, 'recall': 0.0007749935417204857, 'f1': 0.001540041067761807, 'number': 3871}</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.759505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.062000</td>\n",
       "      <td>0.954194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3871}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.803400</td>\n",
       "      <td>0.791773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.08175014392630973, 'recall': 0.03668302764143632, 'f1': 0.050641940085592016, 'number': 3871}</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>0.013291</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>0.774868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.712700</td>\n",
       "      <td>0.707480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.3492063492063492, 'recall': 0.0062006764374295375, 'f1': 0.012184990307394072, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.13287153652392947, 'recall': 0.16352363730302247, 'f1': 0.14661262304574407, 'number': 3871}</td>\n",
       "      <td>0.135695</td>\n",
       "      <td>0.061307</td>\n",
       "      <td>0.084456</td>\n",
       "      <td>0.795682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.673117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.3781818181818182, 'recall': 0.029312288613303268, 'f1': 0.05440753335077165, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.13450917512916444, 'recall': 0.19504004133298888, 'f1': 0.15921552087726698, 'number': 3871}</td>\n",
       "      <td>0.145890</td>\n",
       "      <td>0.080401</td>\n",
       "      <td>0.103669</td>\n",
       "      <td>0.801315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.650704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.0009000900090009, 'f1': 0.0017985611510791368, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4458955223880597, 'recall': 0.06736189402480271, 'f1': 0.11704211557296769, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.13070679742982752, 'recall': 0.1996900025833118, 'f1': 0.15799693408277976, 'number': 3871}</td>\n",
       "      <td>0.157030</td>\n",
       "      <td>0.094815</td>\n",
       "      <td>0.118238</td>\n",
       "      <td>0.805233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.628092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.0036003600360036, 'f1': 0.007174887892376682, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.46799580272822666, 'recall': 0.12570462232243518, 'f1': 0.19817818262608308, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.13511245384357168, 'recall': 0.20795660036166366, 'f1': 0.16380099704954726, 'number': 3871}</td>\n",
       "      <td>0.181490</td>\n",
       "      <td>0.117465</td>\n",
       "      <td>0.142622</td>\n",
       "      <td>0.812566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.612114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.8571428571428571, 'recall': 0.032403240324032405, 'f1': 0.06244579358196011, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.45932325413966885, 'recall': 0.1798196166854566, 'f1': 0.2584565525622848, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.13353464183861768, 'recall': 0.2056316197365022, 'f1': 0.16192026037428806, 'number': 3871}</td>\n",
       "      <td>0.198864</td>\n",
       "      <td>0.137589</td>\n",
       "      <td>0.162647</td>\n",
       "      <td>0.817116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.645700</td>\n",
       "      <td>0.593706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.8146067415730337, 'recall': 0.13051305130513052, 'f1': 0.22498060512024826, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4638447971781305, 'recall': 0.22237880496054116, 'f1': 0.30062869117927227, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.1389801210025929, 'recall': 0.20769826918109016, 'f1': 0.16652858326429162, 'number': 3871}</td>\n",
       "      <td>0.226775</td>\n",
       "      <td>0.162673</td>\n",
       "      <td>0.189448</td>\n",
       "      <td>0.823495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.582100</td>\n",
       "      <td>0.580647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.8085106382978723, 'recall': 0.27362736273627364, 'f1': 0.40887693342299936, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4465875370919881, 'recall': 0.2545095828635851, 'f1': 0.3242369838420108, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.14759358288770053, 'recall': 0.21389821751485405, 'f1': 0.17466511971311044, 'number': 3871}</td>\n",
       "      <td>0.254057</td>\n",
       "      <td>0.190472</td>\n",
       "      <td>0.217717</td>\n",
       "      <td>0.828741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>0.567017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.7918454935622318, 'recall': 0.3321332133213321, 'f1': 0.4679771718452759, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4299913569576491, 'recall': 0.2804396843291995, 'f1': 0.3394745820539065, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.15543278084714549, 'recall': 0.21803151640402996, 'f1': 0.18148586173529724, 'number': 3871}</td>\n",
       "      <td>0.268842</td>\n",
       "      <td>0.206664</td>\n",
       "      <td>0.233688</td>\n",
       "      <td>0.832839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>0.553061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.7302158273381295, 'recall': 0.36543654365436545, 'f1': 0.4871025794841032, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4280618311533888, 'recall': 0.3043968432919955, 'f1': 0.3557898204579147, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.16580805189849265, 'recall': 0.22448979591836735, 'f1': 0.19073748902546092, 'number': 3871}</td>\n",
       "      <td>0.282679</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.247699</td>\n",
       "      <td>0.836783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.596900</td>\n",
       "      <td>0.542237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.7016393442622951, 'recall': 0.3852385238523852, 'f1': 0.49738524113887267, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4261744966442953, 'recall': 0.3221533258173619, 'f1': 0.3669341894060995, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.17381137957911147, 'recall': 0.23043141307155773, 'f1': 0.1981561701655004, 'number': 3871}</td>\n",
       "      <td>0.291652</td>\n",
       "      <td>0.230532</td>\n",
       "      <td>0.257515</td>\n",
       "      <td>0.839490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.549400</td>\n",
       "      <td>0.533874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.6681957186544343, 'recall': 0.3933393339333933, 'f1': 0.4951841359773372, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.02857142857142857, 'recall': 0.0006963788300835655, 'f1': 0.0013596193065941538, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.42642956764295675, 'recall': 0.34470124013528747, 'f1': 0.3812344139650873, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.18012299146994645, 'recall': 0.23456471196073367, 'f1': 0.20377019748653502, 'number': 3871}</td>\n",
       "      <td>0.298790</td>\n",
       "      <td>0.240453</td>\n",
       "      <td>0.266466</td>\n",
       "      <td>0.841397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.523961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.6490455212922174, 'recall': 0.39783978397839787, 'f1': 0.4933035714285714, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.13559322033898305, 'recall': 0.005571030640668524, 'f1': 0.010702341137123745, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.42425249169435214, 'recall': 0.3599210822998873, 'f1': 0.38944800243976824, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.1932994923857868, 'recall': 0.24593128390596744, 'f1': 0.21646202819463392, 'number': 3871}</td>\n",
       "      <td>0.308818</td>\n",
       "      <td>0.250749</td>\n",
       "      <td>0.276770</td>\n",
       "      <td>0.844542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.520465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.6256983240223464, 'recall': 0.40324032403240323, 'f1': 0.4904214559386973, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.00766016713091922, 'f1': 0.014755197853789403, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4196875, 'recall': 0.3785231116121759, 'f1': 0.3980438648488441, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.19420406520426645, 'recall': 0.2492895892534229, 'f1': 0.21832579185520362, 'number': 3871}</td>\n",
       "      <td>0.309508</td>\n",
       "      <td>0.258985</td>\n",
       "      <td>0.282002</td>\n",
       "      <td>0.845354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>0.514944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.624484181568088, 'recall': 0.40864086408640865, 'f1': 0.49401523394994556, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.22388059701492538, 'recall': 0.010445682451253482, 'f1': 0.01996007984031936, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4219793564055859, 'recall': 0.39177001127395716, 'f1': 0.4063139432914353, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.1994669946699467, 'recall': 0.2513562386980108, 'f1': 0.22242542004800547, 'number': 3871}</td>\n",
       "      <td>0.315860</td>\n",
       "      <td>0.265069</td>\n",
       "      <td>0.288244</td>\n",
       "      <td>0.846759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.561500</td>\n",
       "      <td>0.511777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.6212534059945504, 'recall': 0.41044104410441046, 'f1': 0.49430894308943085, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.21348314606741572, 'recall': 0.013231197771587743, 'f1': 0.024918032786885244, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4234016887816647, 'recall': 0.39571589627959414, 'f1': 0.40909090909090906, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.20291640994043952, 'recall': 0.2552312064066133, 'f1': 0.22608695652173913, 'number': 3871}</td>\n",
       "      <td>0.318273</td>\n",
       "      <td>0.268345</td>\n",
       "      <td>0.291184</td>\n",
       "      <td>0.847571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.508771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.6114058355437666, 'recall': 0.41494149414941495, 'f1': 0.49436997319034853, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.22826086956521738, 'recall': 0.014623955431754874, 'f1': 0.027486910994764396, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4208664898320071, 'recall': 0.4024802705749718, 'f1': 0.41146808817173325, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.20841140953570686, 'recall': 0.2585895117540687, 'f1': 0.2308047037122435, 'number': 3871}</td>\n",
       "      <td>0.321942</td>\n",
       "      <td>0.272463</td>\n",
       "      <td>0.295143</td>\n",
       "      <td>0.848718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.523300</td>\n",
       "      <td>0.508644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'precision': 0.6125166444740346, 'recall': 0.414041404140414, 'f1': 0.4940923737916219, 'number': 1111}</td>\n",
       "      <td>{'precision': 0.21875, 'recall': 0.014623955431754874, 'f1': 0.027415143603133157, 'number': 1436}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 718}</td>\n",
       "      <td>{'precision': 0.4213780918727915, 'recall': 0.40332581736189405, 'f1': 0.4121543778801844, 'number': 3548}</td>\n",
       "      <td>{'precision': 0.20698254364089774, 'recall': 0.25729785585120124, 'f1': 0.22941379707474374, 'number': 3871}</td>\n",
       "      <td>0.321149</td>\n",
       "      <td>0.272183</td>\n",
       "      <td>0.294645</td>\n",
       "      <td>0.848473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.718841724216938, metrics={'train_runtime': 192.7602, 'train_samples_per_second': 83.005, 'train_steps_per_second': 2.594, 'total_flos': 113325785088000.0, 'train_loss': 0.718841724216938, 'epoch': 20.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Метрики по сущностям (Train) ===\n",
      "          precision  recall      f1   number\n",
      "GEOPOLIT     0.6509  0.4263  0.5152   4736.0\n",
      "LOC          0.3563  0.0289  0.0534   6440.0\n",
      "MEDIA        0.0000  0.0000  0.0000   2708.0\n",
      "ORG          0.4177  0.4091  0.4134  13890.0\n",
      "PER          0.2102  0.2641  0.2341  15204.0\n",
      "\n",
      "=== Метрики по сущностям (Test) ===\n",
      "          precision  recall      f1  number\n",
      "GEOPOLIT     0.6125  0.4140  0.4941  1111.0\n",
      "LOC          0.2188  0.0146  0.0274  1436.0\n",
      "MEDIA        0.0000  0.0000  0.0000   718.0\n",
      "ORG          0.4214  0.4033  0.4122  3548.0\n",
      "PER          0.2070  0.2573  0.2294  3871.0\n",
      "\n",
      "=== Общие метрики ===\n",
      "                           Train      Test\n",
      "loss                      0.4952    0.5086\n",
      "model_preparation_time    0.0000    0.0000\n",
      "overall_precision         0.3276    0.3211\n",
      "overall_recall            0.2769    0.2722\n",
      "overall_f1                0.3002    0.2946\n",
      "overall_accuracy          0.8501    0.8485\n",
      "runtime                   6.4212    1.7790\n",
      "samples_per_second      124.5870  112.4220\n",
      "steps_per_second          3.8930    3.9350\n"
     ]
    }
   ],
   "source": [
    "results_after_train = ner_trainer.evaluate(\n",
    "    eval_dataset={\"train\": tokenized_ner_datasets[\"train\"], \"test\": tokenized_ner_datasets[\"test\"]}\n",
    ")\n",
    "get_pretty_metrics(results_after_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Сравнение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max_in_group(df, group_col, cols_to_highlight):\n",
    "    def highlight(group):\n",
    "        return group.style.apply(\n",
    "            lambda x: [\"background-color: yellow\" if v == x.max() else \"\" for v in x], subset=cols_to_highlight\n",
    "        )\n",
    "\n",
    "    return df.groupby(group_col, group_keys=False).apply(\n",
    "        lambda x: x.style.apply(\n",
    "            lambda col: [\"background-color: yellow\" if v == col.max() else \"\" for v in col], subset=cols_to_highlight\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bbd1d_row2_col1, #T_bbd1d_row2_col2, #T_bbd1d_row2_col3, #T_bbd1d_row2_col4 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bbd1d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bbd1d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bbd1d_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_bbd1d_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_bbd1d_level0_col3\" class=\"col_heading level0 col3\" >F1</th>\n",
       "      <th id=\"T_bbd1d_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bbd1d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bbd1d_row0_col0\" class=\"data row0 col0\" >without finetuning</td>\n",
       "      <td id=\"T_bbd1d_row0_col1\" class=\"data row0 col1\" >0.0265</td>\n",
       "      <td id=\"T_bbd1d_row0_col2\" class=\"data row0 col2\" >0.1618</td>\n",
       "      <td id=\"T_bbd1d_row0_col3\" class=\"data row0 col3\" >0.0455</td>\n",
       "      <td id=\"T_bbd1d_row0_col4\" class=\"data row0 col4\" >0.0673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbd1d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bbd1d_row1_col0\" class=\"data row1 col0\" >simple finetuning</td>\n",
       "      <td id=\"T_bbd1d_row1_col1\" class=\"data row1 col1\" >0.3221</td>\n",
       "      <td id=\"T_bbd1d_row1_col2\" class=\"data row1 col2\" >0.2792</td>\n",
       "      <td id=\"T_bbd1d_row1_col3\" class=\"data row1 col3\" >0.2991</td>\n",
       "      <td id=\"T_bbd1d_row1_col4\" class=\"data row1 col4\" >0.8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbd1d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bbd1d_row2_col0\" class=\"data row2 col0\" >with mlm pretraining</td>\n",
       "      <td id=\"T_bbd1d_row2_col1\" class=\"data row2 col1\" >0.3791</td>\n",
       "      <td id=\"T_bbd1d_row2_col2\" class=\"data row2 col2\" >0.3404</td>\n",
       "      <td id=\"T_bbd1d_row2_col3\" class=\"data row2 col3\" >0.3587</td>\n",
       "      <td id=\"T_bbd1d_row2_col4\" class=\"data row2 col4\" >0.8676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bbd1d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bbd1d_row3_col0\" class=\"data row3 col0\" >with synthetic labeling</td>\n",
       "      <td id=\"T_bbd1d_row3_col1\" class=\"data row3 col1\" >0.3211</td>\n",
       "      <td id=\"T_bbd1d_row3_col2\" class=\"data row3 col2\" >0.2722</td>\n",
       "      <td id=\"T_bbd1d_row3_col3\" class=\"data row3 col3\" >0.2946</td>\n",
       "      <td id=\"T_bbd1d_row3_col4\" class=\"data row3 col4\" >0.8485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a9441e9910>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_metrics_data = {\n",
    "    \"Model\": [\"without finetuning\", \"simple finetuning\", \"with mlm pretraining\", \"with synthetic labeling\"],\n",
    "    \"Precision\": [0.0265, 0.3221, 0.3791, 0.3211],\n",
    "    \"Recall\": [0.1618, 0.2792, 0.3404, 0.2722],\n",
    "    \"F1\": [0.0455, 0.2991, 0.3587, 0.2946],\n",
    "    \"Accuracy\": [0.0673, 0.8490, 0.8676, 0.8485],\n",
    "}\n",
    "\n",
    "df_general = pd.DataFrame(general_metrics_data)\n",
    "\n",
    "styled_general = df_general.style.highlight_max(axis=0, subset=df_general.columns[1:], color=\"green\")\n",
    "styled_general = styled_general.format(precision=4)\n",
    "\n",
    "# По общим метрикам видно, что предобучение с MLM дало прирост по всем метрикам,\n",
    "# тогда как использование синтетической разметки даже немного ухудшило изначальный результат.\n",
    "# Это связано с тем, что не все теги были представлены в разметке более умной* модели\n",
    "styled_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entity_data = {\n",
    "    \"Model\": [\"without finetuning\"] * 5\n",
    "    + [\"simple finetuning\"] * 5\n",
    "    + [\"with mlm pretraining\"] * 5\n",
    "    + [\"with synthetic labeling\"] * 5,\n",
    "    \"Entity\": [\"GEOPOLIT\", \"LOC\", \"MEDIA\", \"ORG\", \"PER\"] * 4,\n",
    "    \"Precision\": [\n",
    "        0.0062,\n",
    "        0.0099,\n",
    "        0.0034,\n",
    "        0.0478,\n",
    "        0.0361,\n",
    "        0.7111,\n",
    "        0.4259,\n",
    "        0.1000,\n",
    "        0.4036,\n",
    "        0.2008,\n",
    "        0.7306,\n",
    "        0.2637,\n",
    "        0.0000,\n",
    "        0.4364,\n",
    "        0.2597,\n",
    "        0.6125,\n",
    "        0.2188,\n",
    "        0.0000,\n",
    "        0.4214,\n",
    "        0.2070,\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        0.0279,\n",
    "        0.0738,\n",
    "        0.0571,\n",
    "        0.2255,\n",
    "        0.1940,\n",
    "        0.3699,\n",
    "        0.0160,\n",
    "        0.0014,\n",
    "        0.4583,\n",
    "        0.2382,\n",
    "        0.3735,\n",
    "        0.0501,\n",
    "        0.0000,\n",
    "        0.6105,\n",
    "        0.2542,\n",
    "        0.4140,\n",
    "        0.0146,\n",
    "        0.0000,\n",
    "        0.4033,\n",
    "        0.2573,\n",
    "    ],\n",
    "    \"F1\": [\n",
    "        0.0101,\n",
    "        0.0175,\n",
    "        0.0064,\n",
    "        0.0789,\n",
    "        0.0609,\n",
    "        0.4867,\n",
    "        0.0309,\n",
    "        0.0027,\n",
    "        0.4292,\n",
    "        0.2179,\n",
    "        0.4943,\n",
    "        0.0843,\n",
    "        0.0000,\n",
    "        0.5090,\n",
    "        0.2569,\n",
    "        0.4941,\n",
    "        0.0274,\n",
    "        0.0000,\n",
    "        0.4122,\n",
    "        0.2294,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_entities = pd.DataFrame(entity_data)\n",
    "\n",
    "# Переформатируем данные для построения графика\n",
    "melted = df_entities.melt(\n",
    "    id_vars=[\"Model\", \"Entity\"], value_vars=[\"Precision\", \"Recall\", \"F1\"], var_name=\"Metric\", value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Устанавливаем стиль графика\n",
    "sns.set_theme()\n",
    "\n",
    "# Строим график: для каждой метрики по 4 столбца (по моделям)\n",
    "chart = sns.catplot(\n",
    "    data=melted,\n",
    "    kind=\"bar\",\n",
    "    x=\"Entity\",\n",
    "    y=\"Value\",\n",
    "    hue=\"Model\",\n",
    "    col=\"Metric\",\n",
    "    palette=\"viridis\",\n",
    "    height=5,\n",
    "    aspect=1,\n",
    "    legend_out=False,\n",
    ")\n",
    "\n",
    "chart.set_titles(\"{col_name}\")\n",
    "chart.set_axis_labels(\"Entity\", \"Value\")\n",
    "chart.set(ylim=(0, 1))\n",
    "chart._legend.set_title(\"Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Главные выводы, которые можно сделать из графиков:**\n",
    "1. Ориентируясь только на Precision и Recall, не получается выделить лучшую модель. По F1 лучшей моделью в каждой категории оказалась модель с предобучением на MLM задачу.\n",
    "2. У тега MEDIA было наименьшее количество элементов, поэтому почти никакая модель не предсказывала его. \n",
    "3. Использование синтетической разметки только усугубило проблему дисбаланса классов, так как было всего 3 из 5 изначальных тегов.\n",
    "4. Без дообучения модель практически не справляется ни с одной категорией, тк классификационная голова не дообучена и предопределена рандомом. Простое дообучение и особенно MLM pretraining значительно улучшают результаты.\n",
    "5. Синтетическая разметка даёт переменные результаты — иногда помогает (например, Recall для GEOPOLIT), иногда наоборот ухудшает."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
