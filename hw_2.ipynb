{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание 2 - 10 баллов\n",
    "\n",
    "В этом задании вам предстоит продолжить работу с датасетом lenta-ru-news для той же задачи - классификации текстов по топикам. Можно переиспользовать подготовленные данные из ДЗ 1 или загрузить их заново.\n",
    "\n",
    "1. Разделите датасет на обучающую, валидационную и тестовую выборки со стратификацией в пропорции 60/20/20. В качестве целевой переменной используйте атрибут `topic`\n",
    "2. Обучите word2vec-эмбеддинги с помощью библиотеки gensim - **2 балла**\n",
    "  - создайте модель для обучения на ваших данных, опишите, какими значениями вы инициализировали гиперпараметры модели, и почему\n",
    "  - визуально оцените внутреннее (intrinsic) качество получившихся эмбеддингов, используя методы gensim - doesnt_match, most_similar\n",
    "3. Загрузите предобученные эмбеддинги из navec и rusvectores (на ваш вкус) - **1 балл**\n",
    "4. Обучите модель `sklearn.linear_model.LogisticRegression` с тремя вариантами векторизации текстов и сравните их качество между собой на валидационной выборке: **2 балла**\n",
    "  - ваши эмбеддинги w2v\n",
    "  - предобученные эмбеддинги navec\n",
    "  - предобученные эмбеддинги rusvectores\n",
    "5. Попробуйте улучшить качество модели, взяв для ее обучения лучший набор эмбеддингов и используя его с взвешиванием через tf-idf. То есть, необходимо каждый текст представить в виде взвешенного усреднения эмбеддингов его слов, где весами являются соответствующие коэффициенты tf-idf - **2 балла**\n",
    "6. Финально сравните качество всех моделей на тестовой выборке - **1 балл**\n",
    "\n",
    "\n",
    "**Общее**\n",
    "\n",
    "- Принимаемые решения обоснованы (почему выбрана определенная архитектура/гиперпараметр/оптимизатор/преобразование и т.п.) - **1 балл**\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **1 балл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.models\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from navec import Navec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Названы регионы России с самой высокой смертно...</td>\n",
       "      <td>Вице-премьер по социальным вопросам Татьяна Го...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>вице премьер социальным вопросам татьяна голик...</td>\n",
       "      <td>вица премьер социальный вопрос татьяна голиков...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Австрия не представила доказательств вины росс...</td>\n",
       "      <td>Австрийские правоохранительные органы не предс...</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>австрийские правоохранительные органы представ...</td>\n",
       "      <td>австрийский правоохранительный орган представл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Обнаружено самое счастливое место на планете</td>\n",
       "      <td>Сотрудники социальной сети Instagram проанализ...</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>сотрудники социальной сети проанализировали по...</td>\n",
       "      <td>сотрудник социальный сеть проанализировать пос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В США раскрыли сумму расходов на расследование...</td>\n",
       "      <td>С начала расследования российского вмешательст...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>начала расследования российского вмешательства...</td>\n",
       "      <td>начинать расследование российский вмешательств...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Хакеры рассказали о планах Великобритании зами...</td>\n",
       "      <td>Хакерская группировка Anonymous опубликовала н...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>хакерская группировка опубликовала новые докум...</td>\n",
       "      <td>хакерский группировка опубликовывать новый док...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Названы регионы России с самой высокой смертно...   \n",
       "1  Австрия не представила доказательств вины росс...   \n",
       "2       Обнаружено самое счастливое место на планете   \n",
       "3  В США раскрыли сумму расходов на расследование...   \n",
       "4  Хакеры рассказали о планах Великобритании зами...   \n",
       "\n",
       "                                                text        topic  \\\n",
       "0  Вице-премьер по социальным вопросам Татьяна Го...       Россия   \n",
       "1  Австрийские правоохранительные органы не предс...        Спорт   \n",
       "2  Сотрудники социальной сети Instagram проанализ...  Путешествия   \n",
       "3  С начала расследования российского вмешательст...          Мир   \n",
       "4  Хакерская группировка Anonymous опубликовала н...          Мир   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  вице премьер социальным вопросам татьяна голик...   \n",
       "1  австрийские правоохранительные органы представ...   \n",
       "2  сотрудники социальной сети проанализировали по...   \n",
       "3  начала расследования российского вмешательства...   \n",
       "4  хакерская группировка опубликовала новые докум...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  вица премьер социальный вопрос татьяна голиков...  \n",
       "1  австрийский правоохранительный орган представл...  \n",
       "2  сотрудник социальный сеть проанализировать пос...  \n",
       "3  начинать расследование российский вмешательств...  \n",
       "4  хакерский группировка опубликовывать новый док...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружу уже предобработанные тексты из hw_1\n",
    "df = pd.read_csv('data/clean_lenta-ru-news.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               15151\n",
       "Мир                  14421\n",
       "Спорт                10045\n",
       "Экономика             7682\n",
       "Интернет и СМИ        6935\n",
       "Силовые структуры     6925\n",
       "Бывший СССР           6810\n",
       "Культура              6578\n",
       "Наука и техника       5645\n",
       "Из жизни              4903\n",
       "Ценности              4480\n",
       "Дом                   3408\n",
       "Путешествия           3223\n",
       "Бизнес                1993\n",
       "69-я параллель         815\n",
       "Крым                   661\n",
       "Культпросвет           307\n",
       "Оружие                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59989,), (19996,), (19997,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# у меня получилось так, что topic Оружие встретился всего 1 раз,\n",
    "# поэтому пришлось его удалить из-за невозможности стратификации\n",
    "df = df[df['topic'] != 'Оружие']\n",
    "\n",
    "df = df.dropna()\n",
    "X = df['lemmatized_text'].str.split()\n",
    "y = df['topic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение W2V эмбеддингов с gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('питомец', 0.6081347465515137),\n",
       " ('кот', 0.5931268334388733),\n",
       " ('собака', 0.5848177671432495),\n",
       " ('котенок', 0.5780510902404785),\n",
       " ('кролик', 0.5720377564430237)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    sentences=X_train,\n",
    "    vector_size=300,  # потому что датасет не большой и эмбеддинги длиннее могут не выучиться\n",
    "    window=5,  # максимальное расстояние между текущим и предсказанным словом, просто взяла base значение\n",
    "    min_count=10,  # чтобы слово встречалось хотя бы 10 раз, можно поставить и 50\n",
    "    negative=10,  # эпох не очень много, поэтому поставила не 5, чтобы как можно быльше слов при обучении как-то изменялись\n",
    "    epochs=25,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "model.wv.most_similar(positive=['кошка'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'кролик'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['азия', 'европа', 'америка', 'бразилия', 'кролик'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуально качество неплохое, общие зависимости слов улавливает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Загрузка векторов navec/rusvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 25.4M    0  207k    0     0   151k      0  0:02:52  0:00:01  0:02:51  151k\n",
      "  4 25.4M    4 1087k    0     0   455k      0  0:00:57  0:00:02  0:00:55  455k\n",
      "  7 25.4M    7 1986k    0     0   599k      0  0:00:43  0:00:03  0:00:40  599k\n",
      " 12 25.4M   12 3364k    0     0   782k      0  0:00:33  0:00:04  0:00:29  782k\n",
      " 18 25.4M   18 4925k    0     0   928k      0  0:00:28  0:00:05  0:00:23  992k\n",
      " 26 25.4M   26 6913k    0     0  1096k      0  0:00:23  0:00:06  0:00:17 1360k\n",
      " 35 25.4M   35 9129k    0     0  1250k      0  0:00:20  0:00:07  0:00:13 1636k\n",
      " 44 25.4M   44 11.2M    0     0  1389k      0  0:00:18  0:00:08  0:00:10 1915k\n",
      " 52 25.4M   52 13.4M    0     0  1478k      0  0:00:17  0:00:09  0:00:08 2076k\n",
      " 64 25.4M   64 16.4M    0     0  1625k      0  0:00:16  0:00:10  0:00:06 2359k\n",
      " 79 25.4M   79 20.0M    0     0  1801k      0  0:00:14  0:00:11  0:00:03 2669k\n",
      " 95 25.4M   95 24.2M    0     0  2014k      0  0:00:12  0:00:12 --:--:-- 3130k\n",
      "100 25.4M  100 25.4M    0     0  2070k      0  0:00:12  0:00:12 --:--:-- 3397k\n"
     ]
    }
   ],
   "source": [
    "# !curl -L -o data/navec_news_v1_1B_250K_300d_100q.tar https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  376M    0 1156k    0     0  3516k      0  0:01:49 --:--:--  0:01:49 3525k\n",
      "  2  376M    2 11.2M    0     0  8694k      0  0:00:44  0:00:01  0:00:43 8696k\n",
      "  5  376M    5 20.8M    0     0  9169k      0  0:00:42  0:00:02  0:00:40 9172k\n",
      "  8  376M    8 31.1M    0     0  9598k      0  0:00:40  0:00:03  0:00:37 9600k\n",
      " 11  376M   11 41.5M    0     0  9841k      0  0:00:39  0:00:04  0:00:35 9844k\n",
      " 13  376M   13 52.1M    0     0   9.7M      0  0:00:38  0:00:05  0:00:33 10.1M\n",
      " 16  376M   16 62.7M    0     0   9.9M      0  0:00:37  0:00:06  0:00:31 10.2M\n",
      " 19  376M   19 73.1M    0     0   9.9M      0  0:00:37  0:00:07  0:00:30 10.4M\n",
      " 21  376M   21 81.9M    0     0   9.8M      0  0:00:38  0:00:08  0:00:30 10.1M\n",
      " 24  376M   24 91.9M    0     0   9.8M      0  0:00:38  0:00:09  0:00:29 10.0M\n",
      " 26  376M   26  101M    0     0   9.7M      0  0:00:38  0:00:10  0:00:28  9.8M\n",
      " 29  376M   29  110M    0     0   9.7M      0  0:00:38  0:00:11  0:00:27 9857k\n",
      " 32  376M   32  120M    0     0   9.8M      0  0:00:38  0:00:12  0:00:26 9790k\n",
      " 34  376M   34  131M    0     0   9.8M      0  0:00:38  0:00:13  0:00:25  9.8M\n",
      " 37  376M   37  140M    0     0   9.8M      0  0:00:38  0:00:14  0:00:24 9971k\n",
      " 39  376M   39  150M    0     0   9.8M      0  0:00:38  0:00:15  0:00:23  9.8M\n",
      " 42  376M   42  160M    0     0   9.8M      0  0:00:38  0:00:16  0:00:22  9.9M\n",
      " 45  376M   45  169M    0     0   9.7M      0  0:00:38  0:00:17  0:00:21  9.7M\n",
      " 47  376M   47  180M    0     0   9.8M      0  0:00:38  0:00:18  0:00:20  9.8M\n",
      " 50  376M   50  189M    0     0   9.8M      0  0:00:38  0:00:19  0:00:19  9.8M\n",
      " 53  376M   53  200M    0     0   9.8M      0  0:00:38  0:00:20  0:00:18 10.0M\n",
      " 56  376M   56  210M    0     0   9.8M      0  0:00:38  0:00:21  0:00:17 10.0M\n",
      " 58  376M   58  219M    0     0   9.8M      0  0:00:38  0:00:22  0:00:16 10.0M\n",
      " 61  376M   61  230M    0     0   9.8M      0  0:00:38  0:00:23  0:00:15 10.0M\n",
      " 63  376M   63  240M    0     0   9.9M      0  0:00:38  0:00:24  0:00:14 10.1M\n",
      " 66  376M   66  251M    0     0   9.9M      0  0:00:37  0:00:25  0:00:12 10.0M\n",
      " 69  376M   69  261M    0     0   9.9M      0  0:00:37  0:00:26  0:00:11 10.1M\n",
      " 72  376M   72  271M    0     0   9.9M      0  0:00:37  0:00:27  0:00:10 10.3M\n",
      " 74  376M   74  281M    0     0   9.9M      0  0:00:37  0:00:28  0:00:09 10.1M\n",
      " 77  376M   77  290M    0     0   9.9M      0  0:00:37  0:00:29  0:00:08  9.9M\n",
      " 79  376M   79  299M    0     0   9.8M      0  0:00:38  0:00:30  0:00:08 9996k\n",
      " 82  376M   82  310M    0     0   9.9M      0  0:00:37  0:00:31  0:00:06  9.8M\n",
      " 85  376M   85  320M    0     0   9.9M      0  0:00:37  0:00:32  0:00:05  9.8M\n",
      " 87  376M   87  330M    0     0   9.9M      0  0:00:37  0:00:33  0:00:04  9.8M\n",
      " 90  376M   90  340M    0     0   9.9M      0  0:00:37  0:00:34  0:00:03  9.9M\n",
      " 93  376M   93  351M    0     0   9.9M      0  0:00:37  0:00:35  0:00:02 10.2M\n",
      " 96  376M   96  361M    0     0   9.9M      0  0:00:37  0:00:36  0:00:01 10.1M\n",
      " 98  376M   98  371M    0     0   9.9M      0  0:00:37  0:00:37 --:--:-- 10.1M\n",
      "100  376M  100  376M    0     0   9.9M      0  0:00:37  0:00:37 --:--:-- 10.2M\n"
     ]
    }
   ],
   "source": [
    "# !curl -L -o data/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz https://rusvectores.org/static/models/rusvectores4/ruwikiruscorpora/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec_model = Navec.load('data/navec_news_v1_1B_250K_300d_100q.tar')\n",
    "rusvectores_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    'data/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(texts: list[list], model, dim: int) -> np.array:\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        vectors.append(\n",
    "            np.mean([model[word] for word in text if word in model], axis=0)\n",
    "            if any(word in model for word in text)\n",
    "            else np.zeros(dim)\n",
    "        )\n",
    "    return np.array(vectors)\n",
    "\n",
    "\n",
    "train_w2v = text_to_vector(X_train, model.wv, 256)\n",
    "val_w2v = text_to_vector(X_val, model.wv, 256)\n",
    "test_w2v = text_to_vector(X_test, model.wv, 256)\n",
    "\n",
    "train_navec = text_to_vector(X_train, navec_model, 300)\n",
    "val_navec = text_to_vector(X_val, navec_model, 300)\n",
    "test_navec = text_to_vector(X_test, navec_model, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('ru_core_news_sm', enable=['tok2vec', 'morphologizer', 'lemmatizer'])\n",
    "\n",
    "\n",
    "def add_pos_tag(texts: list[list]) -> list[list]:\n",
    "    pos_texts = nlp.pipe([' '.join(text) for text in texts], batch_size=128, n_process=-1)\n",
    "    return [[f'{token.lemma_}_{token.pos_}' for token in text] for text in pos_texts]\n",
    "\n",
    "\n",
    "train_rusvectores = add_pos_tag(X_train)\n",
    "val_rusvectores = add_pos_tag(X_val)\n",
    "test_rusvectores = add_pos_tag(X_test)\n",
    "\n",
    "train_rusvectores = text_to_vector(train_rusvectores, rusvectores_model, 300)\n",
    "val_rusvectores = text_to_vector(val_rusvectores, rusvectores_model, 300)\n",
    "test_rusvectores = text_to_vector(test_rusvectores, rusvectores_model, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обучение логрегрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy векторов на обученном W2V: 0.8106\n",
      "Accuracy векторов Navec: 0.7928\n",
      "Accuracy векторов RucVectores: 0.7264\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(X_train, X_val, y_train, y_val) -> float:\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    return accuracy_score(y_val, y_pred)\n",
    "\n",
    "\n",
    "acc_w2v = train_and_evaluate(train_w2v, val_w2v, y_train, y_val)\n",
    "acc_navec = train_and_evaluate(train_navec, val_navec, y_train, y_val)\n",
    "acc_rusv = train_and_evaluate(train_rusvectores, val_rusvectores, y_train, y_val)\n",
    "\n",
    "print(f'Accuracy векторов на обученном W2V: {acc_w2v:.4f}')\n",
    "print(f'Accuracy векторов Navec: {acc_navec:.4f}')\n",
    "print(f'Accuracy векторов RucVectores: {acc_rusv:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70753    [депутат, верховный, рад, надежда, савченко, з...\n",
       "88036    [управление, росреестр, московский, область, ф...\n",
       "51971    [заявка, сборная, нигер, юношеский, чемпионат,...\n",
       "96472    [кандидат, президент, франция, бывший, премьер...\n",
       "13644    [ученый, гонконгский, баптистский, университет...\n",
       "                               ...                        \n",
       "2934     [любительница, лотерея, американский, штат, ми...\n",
       "97888    [исследователь, медицинский, школа, вашингтонс...\n",
       "50026    [квартира, речной, улица, подмосковный, балаши...\n",
       "45941    [исследователь, манитобский, университет, кана...\n",
       "77912    [стоимость, самый, дорогой, загородный, домовл...\n",
       "Name: lemmatized_text, Length: 59989, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Логрегрессия с TF-IDF взвешиванием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "vectorizer.fit(X_train)\n",
    "tfidf_weights = dict(zip(vectorizer.get_feature_names_out(), vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели на взвешенных векторах обученного W2V: 0.7990\n"
     ]
    }
   ],
   "source": [
    "def weighted_text_to_vector(texts: list[list], model, dim: int, tfidf_weights) -> np.array:\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        word_vectors, weights = [], []\n",
    "        for word in text:\n",
    "            if word in model and word in tfidf_weights:\n",
    "                word_vectors.append(model[word] * tfidf_weights[word])\n",
    "                weights.append(tfidf_weights[word])\n",
    "        vectors.append(np.average(word_vectors, axis=0, weights=weights) if word_vectors else np.zeros(dim))\n",
    "    return np.array(vectors)\n",
    "\n",
    "\n",
    "train_weighted = weighted_text_to_vector(X_train, model.wv, 300, tfidf_weights)\n",
    "val_weighted = weighted_text_to_vector(X_val, model.wv, 300, tfidf_weights)\n",
    "test_weighted = weighted_text_to_vector(X_test, model.wv, 300, tfidf_weights)\n",
    "\n",
    "acc_weighted = train_and_evaluate(train_weighted, val_weighted, y_train, y_val)\n",
    "\n",
    "print(f'Accuracy модели на взвешенных векторах обученного W2V: {acc_weighted:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что качество только упало"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Финальное сравнение на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy векторов на обученном W2V: 0.8007\n",
      "Accuracy взвешенных векторов на обученном W2V: 0.7902\n",
      "Accuracy векторов Navec: 0.7832\n",
      "Accuracy векторов RucVectores: 0.7237\n"
     ]
    }
   ],
   "source": [
    "acc_w2v = train_and_evaluate(train_w2v, test_w2v, y_train, y_test)\n",
    "acc_navec = train_and_evaluate(train_navec, test_navec, y_train, y_test)\n",
    "acc_rusv = train_and_evaluate(train_rusvectores, test_rusvectores, y_train, y_test)\n",
    "acc_weighted_w2v = train_and_evaluate(train_weighted, test_weighted, y_train, y_test)\n",
    "\n",
    "print(f'Accuracy векторов на обученном W2V: {acc_w2v:.4f}')\n",
    "print(f'Accuracy взвешенных векторов на обученном W2V: {acc_weighted_w2v:.4f}')\n",
    "print(f'Accuracy векторов Navec: {acc_navec:.4f}')\n",
    "print(f'Accuracy векторов RucVectores: {acc_rusv:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
