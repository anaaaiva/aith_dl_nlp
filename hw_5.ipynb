{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bad348a",
   "metadata": {},
   "source": [
    "### Домашнее задание 5 - 10 баллов\n",
    "\n",
    "В этом задании вам предстоит дообучить трансформерную модель для задачи классификации с помощью различных техник и сравнить их между собой.\n",
    "\n",
    "Датасет: [dair-ai/emotion](https://huggingface.co/datasets/dair-ai/emotion) \n",
    "\n",
    "Модель: [google-bert/bert-base-uncased](https://huggingface.co/google-bert/bert-base-uncased) (если хочется, можно заменить на что-то более интересное)\n",
    "\n",
    "1. Скачайте датасет и модель. Измерьте базовые метрики классификации перед началом экспериментов.\n",
    "\n",
    "**NB!** Для всех типов дообучения замерьте :\n",
    "- качество классификации на выходе\n",
    "- время дообучения\n",
    "- количество параметров для обучения\n",
    "- потребление ресурсов (не нужно заморачиваться с профайлингом - можно просто посмотреть в `nvidia-smi` или `torch.cuda.memory_allocated`)\n",
    "\n",
    "2. Обучите модель в режиме full finetuning - **1 балл**\n",
    "3. Обучите модель в режиме linear probing - реализуйте кастомную классификационную голову и обучайте только ее. Не забудьте описать, чем обусловлено устройство головы, как вы пришли к такой архитектуре - **2 балла**\n",
    "4. Обучите модель в режиме PEFT с использованием [prompt tuning или prefix tuning](https://ericwiener.github.io/ai-notes/AI-Notes/Large-Language-Models/Prompt-Tuning-and-Prefix-Tuning). При выборе метода напишите пару слов, почему решили остановиться именно на этом методе - **2 балла**\n",
    "4. Обучите модель в режиме PEFT с использованием LoRA. Попробуйте подобрать оптимальный ранг - `r`, при желании поэкспериментируйте с остальными гиперпараметрами. Опишите, чем обусловлена ваша финальная конфигурация - **2 балла**\n",
    "\n",
    "5. Соберите все результаты отдельных замеров в таблицу и сделайте выводы о вычислительной сложности методов, итоговом качестве и прочих наблюдаемых свойствах моделей - **1 балл**\n",
    "\n",
    "**Общее**\n",
    "\n",
    "- Принимаемые решения обоснованы (почему выбрана определенная архитектура/гиперпараметр/оптимизатор/преобразование и т.п.) - **1 балл**\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **1 балл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import evaluate\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, PrefixTuningConfig, TaskType, PromptTuningConfig\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c80f1d8",
   "metadata": {},
   "source": [
    "# 1. Загрузка датасета и модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ec8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "label_list = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(label_list)\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc557e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5362\n",
       "0    4666\n",
       "3    2159\n",
       "4    1937\n",
       "2    1304\n",
       "5     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dataset[\"train\"][\"label\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964140b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCLAIMER: для чистоты эксперимента и из-за ограничения по времени, параметры обучения типа\n",
    "# lr, количества эпох и тд. подбираться не будут, чтобы посмотреть сходимость за фиксированное количество эпох\n",
    "# + для оценки метрик в конце используется лучшая модель среди всех эпох по минимальному валидационному лоссу\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./hw_5\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=1e-4,\n",
    "    seed=SEED,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f8ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"Recall\": recall_metric.compute(predictions=predictions, references=labels, average=\"macro\", zero_division=0)[\n",
    "            \"recall\"\n",
    "        ],\n",
    "        \"Precision\": precision_metric.compute(\n",
    "            predictions=predictions, references=labels, average=\"macro\", zero_division=0\n",
    "        )[\"precision\"],\n",
    "        \"F1\": f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ca0d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 1.1865\n",
      "eval_model_preparation_time: 0.0018\n",
      "eval_Accuracy: 0.5775\n",
      "eval_Recall: 0.3039\n",
      "eval_Precision: 0.2751\n",
      "eval_F1: 0.2425\n",
      "Trainable parameters: 109.49, M\n",
      "CUDA memory used: 1334.25MB\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate(dataset[\"test\"])\n",
    "for metric, value in eval_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "print(f\"Trainable parameters: {(sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6):.2f}, M\")\n",
    "print(f\"CUDA memory used: {(torch.cuda.memory_allocated() / 1e6):.2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a893b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_pretty_print_results(trainer):\n",
    "    start = time.time()\n",
    "    trainer.train()\n",
    "    end = time.time()\n",
    "\n",
    "    eval_results = trainer.evaluate(dataset[\"test\"])\n",
    "    for metric, value in eval_results.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print(\"Training time:\", round(end - start, 2), \"sec\")\n",
    "    print(f\"Trainable parameters: {(sum(p.numel() for p in trainer.model.parameters() if p.requires_grad) / 1e6):.2f}M\")\n",
    "    print(f\"CUDA memory used: {(torch.cuda.memory_allocated() / 1e6):.2f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87630133",
   "metadata": {},
   "source": [
    "# 2. Full finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a40d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 18:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.248381</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>0.906065</td>\n",
       "      <td>0.880939</td>\n",
       "      <td>0.890773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.233923</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.886878</td>\n",
       "      <td>0.904915</td>\n",
       "      <td>0.893152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.173627</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.907931</td>\n",
       "      <td>0.914385</td>\n",
       "      <td>0.905983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.144800</td>\n",
       "      <td>0.302654</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.910205</td>\n",
       "      <td>0.902231</td>\n",
       "      <td>0.904963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.291294</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.929500</td>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.899780</td>\n",
       "      <td>0.904006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.299224</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.929500</td>\n",
       "      <td>0.901708</td>\n",
       "      <td>0.906698</td>\n",
       "      <td>0.903801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.445278</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.898278</td>\n",
       "      <td>0.924899</td>\n",
       "      <td>0.910674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.389718</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.901167</td>\n",
       "      <td>0.921105</td>\n",
       "      <td>0.910464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.391706</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.935500</td>\n",
       "      <td>0.916138</td>\n",
       "      <td>0.901923</td>\n",
       "      <td>0.908733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.390262</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.916783</td>\n",
       "      <td>0.916942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.1965\n",
      "eval_model_preparation_time: 0.0018\n",
      "eval_Accuracy: 0.9235\n",
      "eval_Recall: 0.8891\n",
      "eval_Precision: 0.8951\n",
      "eval_F1: 0.8823\n",
      "eval_runtime: 3.2845\n",
      "eval_samples_per_second: 608.9210\n",
      "eval_steps_per_second: 9.7430\n",
      "epoch: 10.0000\n",
      "Training time: 1127.64 sec\n",
      "Trainable parameters: 109.49M\n",
      "CUDA memory used: 1334.25MB\n"
     ]
    }
   ],
   "source": [
    "train_and_pretty_print_results(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd080d",
   "metadata": {},
   "source": [
    "# 3. Linear probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3515e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 05:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.559700</td>\n",
       "      <td>1.549771</td>\n",
       "      <td>0.429500</td>\n",
       "      <td>0.221127</td>\n",
       "      <td>0.142387</td>\n",
       "      <td>0.170567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.532800</td>\n",
       "      <td>1.521343</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.211117</td>\n",
       "      <td>0.139228</td>\n",
       "      <td>0.161438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.518200</td>\n",
       "      <td>1.510248</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.235398</td>\n",
       "      <td>0.150733</td>\n",
       "      <td>0.181655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.501200</td>\n",
       "      <td>1.502037</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>0.242263</td>\n",
       "      <td>0.153756</td>\n",
       "      <td>0.185876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.492200</td>\n",
       "      <td>1.479818</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.242708</td>\n",
       "      <td>0.154883</td>\n",
       "      <td>0.187507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.484700</td>\n",
       "      <td>1.482899</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>0.248059</td>\n",
       "      <td>0.156442</td>\n",
       "      <td>0.190704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.482400</td>\n",
       "      <td>1.469791</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.244148</td>\n",
       "      <td>0.154711</td>\n",
       "      <td>0.188472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.476900</td>\n",
       "      <td>1.467436</td>\n",
       "      <td>0.474500</td>\n",
       "      <td>0.248731</td>\n",
       "      <td>0.156104</td>\n",
       "      <td>0.191786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.480400</td>\n",
       "      <td>1.465191</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.250530</td>\n",
       "      <td>0.157562</td>\n",
       "      <td>0.193284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.473500</td>\n",
       "      <td>1.463350</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.250672</td>\n",
       "      <td>0.157891</td>\n",
       "      <td>0.193446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 1.4338\n",
      "eval_Accuracy: 0.4645\n",
      "eval_Recall: 0.2388\n",
      "eval_Precision: 0.1532\n",
      "eval_F1: 0.1858\n",
      "eval_runtime: 3.3332\n",
      "eval_samples_per_second: 600.0290\n",
      "eval_steps_per_second: 9.6000\n",
      "epoch: 10.0000\n",
      "Training time: 315.08 sec\n",
      "Trainable parameters: 0.00M\n",
      "CUDA memory used: 1774.06MB\n"
     ]
    }
   ],
   "source": [
    "# загружаем модель и замораживаем encoder, обучается только голова\n",
    "lp_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "for param in lp_model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "lp_model = lp_model.to(device)\n",
    "\n",
    "# используется просто CLS токен → Dropout → Dense → Softmax\n",
    "# простой и эффективный классификатор, минимальные затраты, уже реализованный класс из transformers\n",
    "# остальная часть кода аналогична Full finetuning, кроме `requires_grad = False`\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lp_model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "train_and_pretty_print_results(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6c38d",
   "metadata": {},
   "source": [
    "# 4. Prompt/Prefix tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb2589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 368,640 || all params: 109,855,494 || trainable%: 0.3356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 09:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.714700</td>\n",
       "      <td>1.690119</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>0.167829</td>\n",
       "      <td>0.106241</td>\n",
       "      <td>0.090243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.695200</td>\n",
       "      <td>1.669006</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>0.167829</td>\n",
       "      <td>0.125230</td>\n",
       "      <td>0.090218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.671200</td>\n",
       "      <td>1.647909</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>0.167829</td>\n",
       "      <td>0.125230</td>\n",
       "      <td>0.090218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.647200</td>\n",
       "      <td>1.627662</td>\n",
       "      <td>0.354500</td>\n",
       "      <td>0.168447</td>\n",
       "      <td>0.142286</td>\n",
       "      <td>0.092249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.627800</td>\n",
       "      <td>1.612693</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>0.172405</td>\n",
       "      <td>0.130946</td>\n",
       "      <td>0.104655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.619300</td>\n",
       "      <td>1.602980</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>0.180256</td>\n",
       "      <td>0.123616</td>\n",
       "      <td>0.123184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.615700</td>\n",
       "      <td>1.595963</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.186572</td>\n",
       "      <td>0.128150</td>\n",
       "      <td>0.133435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.605100</td>\n",
       "      <td>1.591501</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.189223</td>\n",
       "      <td>0.128174</td>\n",
       "      <td>0.137469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.606900</td>\n",
       "      <td>1.589112</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>0.192519</td>\n",
       "      <td>0.129324</td>\n",
       "      <td>0.141518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.605400</td>\n",
       "      <td>1.588218</td>\n",
       "      <td>0.389000</td>\n",
       "      <td>0.193598</td>\n",
       "      <td>0.130272</td>\n",
       "      <td>0.142478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 1.5779\n",
      "eval_Accuracy: 0.3820\n",
      "eval_Recall: 0.1901\n",
      "eval_Precision: 0.1284\n",
      "eval_F1: 0.1400\n",
      "eval_runtime: 3.3695\n",
      "eval_samples_per_second: 593.5530\n",
      "eval_steps_per_second: 9.4970\n",
      "epoch: 10.0000\n",
      "Training time: 581.81 sec\n",
      "Trainable parameters: 0.37M\n",
      "CUDA memory used: 2256.85MB\n"
     ]
    }
   ],
   "source": [
    "# prefix tuning мне показался интереснее prompt tuning, потому что он добавляет обучаемые векторы прямо\n",
    "# в attention внутри модели, а не просто в начало текста. то есть влияние этих токенов по идее должно быть\n",
    "# глубже и сильнее, что может быть полезно в задачах с тонкими различиями, как эмоции. да, он чуть тяжелее\n",
    "# по памяти, но не сильно. также прочитала, что он лучше работает на меньших моделях (типа bert)\n",
    "\n",
    "peft_config = PrefixTuningConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    num_virtual_tokens=20,  # средний стартовый вариант для большинства задач\n",
    ")\n",
    "\n",
    "peft_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "peft_model = get_peft_model(peft_model, peft_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "peft_model.to(device)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "train_and_pretty_print_results(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 15,360 || all params: 109,502,214 || trainable%: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 13:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.685900</td>\n",
       "      <td>1.625574</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.167036</td>\n",
       "      <td>0.125397</td>\n",
       "      <td>0.088023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.635000</td>\n",
       "      <td>1.585426</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.212614</td>\n",
       "      <td>0.151385</td>\n",
       "      <td>0.168040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.607100</td>\n",
       "      <td>1.544583</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.227292</td>\n",
       "      <td>0.186456</td>\n",
       "      <td>0.179919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.580700</td>\n",
       "      <td>1.604632</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.248977</td>\n",
       "      <td>0.202094</td>\n",
       "      <td>0.213545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.572100</td>\n",
       "      <td>1.541590</td>\n",
       "      <td>0.459500</td>\n",
       "      <td>0.282803</td>\n",
       "      <td>0.218746</td>\n",
       "      <td>0.245001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.555100</td>\n",
       "      <td>1.515897</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>0.287623</td>\n",
       "      <td>0.216768</td>\n",
       "      <td>0.245038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.553700</td>\n",
       "      <td>1.514201</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.282538</td>\n",
       "      <td>0.208013</td>\n",
       "      <td>0.232230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.533400</td>\n",
       "      <td>1.514675</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.279261</td>\n",
       "      <td>0.203578</td>\n",
       "      <td>0.224996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.535800</td>\n",
       "      <td>1.507338</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.282102</td>\n",
       "      <td>0.205779</td>\n",
       "      <td>0.228656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.533200</td>\n",
       "      <td>1.495184</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.289934</td>\n",
       "      <td>0.212549</td>\n",
       "      <td>0.238143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 1.4769\n",
      "eval_Accuracy: 0.4750\n",
      "eval_Recall: 0.2989\n",
      "eval_Precision: 0.2231\n",
      "eval_F1: 0.2508\n",
      "eval_runtime: 4.5304\n",
      "eval_samples_per_second: 441.4670\n",
      "eval_steps_per_second: 7.0630\n",
      "epoch: 10.0000\n",
      "Training time: 780.66 sec\n",
      "Trainable parameters: 0.02M\n",
      "CUDA memory used: 1804.14MB\n"
     ]
    }
   ],
   "source": [
    "# однако из-за того, что prefix tuning показал такие плохие метрики (как бы я не меняла параметры), решила попробовать и prompt tuning\n",
    "# в итоге я остановилась на нем из-за лучших метрик. он позволяет дообучать только маленькое количество виртуальных токенов,\n",
    "# которые добавляются в начало входа. это суперэффективный способ, особенно если нет возможности гонять всю модель.\n",
    "# ещё один плюс — его легко внедрить через готовые инструменты, и он не требует изменений внутри самой модели.\n",
    "\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    prompt_tuning_init=\"TEXT\",\n",
    "    prompt_tuning_init_text=\"Classify the emotion in this sentence.\",\n",
    "    num_virtual_tokens=20,  #\n",
    "    tokenizer_name_or_path=model_name,\n",
    ")\n",
    "\n",
    "peft_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "peft_model = get_peft_model(peft_model, peft_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "peft_model.to(device)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "train_and_pretty_print_results(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdeef11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ef02a87",
   "metadata": {},
   "source": [
    "# 5. LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2273541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 78,342 || all params: 109,565,196 || trainable%: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 09:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.042700</td>\n",
       "      <td>0.864485</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.466521</td>\n",
       "      <td>0.623927</td>\n",
       "      <td>0.426045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.678900</td>\n",
       "      <td>0.593508</td>\n",
       "      <td>0.798500</td>\n",
       "      <td>0.684998</td>\n",
       "      <td>0.778109</td>\n",
       "      <td>0.707712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.510800</td>\n",
       "      <td>0.435054</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.795782</td>\n",
       "      <td>0.837918</td>\n",
       "      <td>0.809244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.420100</td>\n",
       "      <td>0.366360</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>0.842800</td>\n",
       "      <td>0.863781</td>\n",
       "      <td>0.849898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.311671</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.859371</td>\n",
       "      <td>0.879360</td>\n",
       "      <td>0.867804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>0.286943</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>0.869974</td>\n",
       "      <td>0.899727</td>\n",
       "      <td>0.882965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.271764</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.876701</td>\n",
       "      <td>0.885065</td>\n",
       "      <td>0.880121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>0.258155</td>\n",
       "      <td>0.916500</td>\n",
       "      <td>0.895832</td>\n",
       "      <td>0.886111</td>\n",
       "      <td>0.890709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.260740</td>\n",
       "      <td>0.918500</td>\n",
       "      <td>0.888034</td>\n",
       "      <td>0.892492</td>\n",
       "      <td>0.889460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.250059</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.887352</td>\n",
       "      <td>0.885295</td>\n",
       "      <td>0.886033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.2273\n",
      "eval_Accuracy: 0.9180\n",
      "eval_Recall: 0.8657\n",
      "eval_Precision: 0.8792\n",
      "eval_F1: 0.8717\n",
      "eval_runtime: 3.3366\n",
      "eval_samples_per_second: 599.4070\n",
      "eval_steps_per_second: 9.5910\n",
      "epoch: 10.0000\n",
      "Training time: 595.34 sec\n",
      "Trainable parameters: 0.08M\n",
      "CUDA memory used: 2260.31MB\n",
      "\n",
      "R =  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 152,070 || all params: 109,638,924 || trainable%: 0.1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 09:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.011600</td>\n",
       "      <td>0.817671</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>0.510448</td>\n",
       "      <td>0.560067</td>\n",
       "      <td>0.494984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.533662</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>0.700518</td>\n",
       "      <td>0.806409</td>\n",
       "      <td>0.725835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468700</td>\n",
       "      <td>0.385553</td>\n",
       "      <td>0.868500</td>\n",
       "      <td>0.798170</td>\n",
       "      <td>0.849376</td>\n",
       "      <td>0.814545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.324968</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.839343</td>\n",
       "      <td>0.866545</td>\n",
       "      <td>0.847885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.272506</td>\n",
       "      <td>0.910500</td>\n",
       "      <td>0.879915</td>\n",
       "      <td>0.884522</td>\n",
       "      <td>0.881816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>0.253953</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>0.883399</td>\n",
       "      <td>0.898054</td>\n",
       "      <td>0.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>0.239597</td>\n",
       "      <td>0.919000</td>\n",
       "      <td>0.884791</td>\n",
       "      <td>0.896743</td>\n",
       "      <td>0.889786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.236536</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.906596</td>\n",
       "      <td>0.893005</td>\n",
       "      <td>0.899394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.235098</td>\n",
       "      <td>0.923500</td>\n",
       "      <td>0.898434</td>\n",
       "      <td>0.897025</td>\n",
       "      <td>0.897375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.239800</td>\n",
       "      <td>0.229153</td>\n",
       "      <td>0.925500</td>\n",
       "      <td>0.900072</td>\n",
       "      <td>0.900297</td>\n",
       "      <td>0.899784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.2281\n",
      "eval_Accuracy: 0.9220\n",
      "eval_Recall: 0.8755\n",
      "eval_Precision: 0.8801\n",
      "eval_F1: 0.8764\n",
      "eval_runtime: 3.3300\n",
      "eval_samples_per_second: 600.5920\n",
      "eval_steps_per_second: 9.6090\n",
      "epoch: 10.0000\n",
      "Training time: 596.71 sec\n",
      "Trainable parameters: 0.15M\n",
      "CUDA memory used: 2254.64MB\n",
      "\n",
      "R =  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 299,526 || all params: 109,786,380 || trainable%: 0.2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 09:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.018300</td>\n",
       "      <td>0.837264</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>0.501918</td>\n",
       "      <td>0.594980</td>\n",
       "      <td>0.479230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.616400</td>\n",
       "      <td>0.506274</td>\n",
       "      <td>0.831500</td>\n",
       "      <td>0.726280</td>\n",
       "      <td>0.819525</td>\n",
       "      <td>0.752434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.450500</td>\n",
       "      <td>0.357620</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.807298</td>\n",
       "      <td>0.858432</td>\n",
       "      <td>0.824504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.310631</td>\n",
       "      <td>0.894500</td>\n",
       "      <td>0.837525</td>\n",
       "      <td>0.870705</td>\n",
       "      <td>0.848313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.260805</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>0.889466</td>\n",
       "      <td>0.893021</td>\n",
       "      <td>0.890998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.290900</td>\n",
       "      <td>0.235847</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>0.888774</td>\n",
       "      <td>0.900566</td>\n",
       "      <td>0.893979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.232797</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.901691</td>\n",
       "      <td>0.892255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.232567</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.895609</td>\n",
       "      <td>0.890515</td>\n",
       "      <td>0.892878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.236800</td>\n",
       "      <td>0.226265</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.892683</td>\n",
       "      <td>0.903225</td>\n",
       "      <td>0.897165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.903928</td>\n",
       "      <td>0.901996</td>\n",
       "      <td>0.902514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.2178\n",
      "eval_Accuracy: 0.9215\n",
      "eval_Recall: 0.8729\n",
      "eval_Precision: 0.8871\n",
      "eval_F1: 0.8780\n",
      "eval_runtime: 3.3137\n",
      "eval_samples_per_second: 603.5640\n",
      "eval_steps_per_second: 9.6570\n",
      "epoch: 10.0000\n",
      "Training time: 599.53 sec\n",
      "Trainable parameters: 0.30M\n",
      "CUDA memory used: 2254.84MB\n",
      "\n",
      "R =  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 594,438 || all params: 110,081,292 || trainable%: 0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 10:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.005600</td>\n",
       "      <td>0.801349</td>\n",
       "      <td>0.706500</td>\n",
       "      <td>0.508285</td>\n",
       "      <td>0.567780</td>\n",
       "      <td>0.491888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.596300</td>\n",
       "      <td>0.480032</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.726947</td>\n",
       "      <td>0.812526</td>\n",
       "      <td>0.752939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.352922</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0.811976</td>\n",
       "      <td>0.855346</td>\n",
       "      <td>0.826306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.300128</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.851319</td>\n",
       "      <td>0.886119</td>\n",
       "      <td>0.861156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>0.257592</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>0.881176</td>\n",
       "      <td>0.886431</td>\n",
       "      <td>0.883591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.276300</td>\n",
       "      <td>0.231707</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.883698</td>\n",
       "      <td>0.907530</td>\n",
       "      <td>0.893142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.223209</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.885602</td>\n",
       "      <td>0.902146</td>\n",
       "      <td>0.892371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>0.222584</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.898228</td>\n",
       "      <td>0.901006</td>\n",
       "      <td>0.899307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>0.214144</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.889906</td>\n",
       "      <td>0.906710</td>\n",
       "      <td>0.896719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.211572</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.895065</td>\n",
       "      <td>0.906138</td>\n",
       "      <td>0.899162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.2199\n",
      "eval_Accuracy: 0.9220\n",
      "eval_Recall: 0.8733\n",
      "eval_Precision: 0.8934\n",
      "eval_F1: 0.8793\n",
      "eval_runtime: 3.3092\n",
      "eval_samples_per_second: 604.3830\n",
      "eval_steps_per_second: 9.6700\n",
      "epoch: 10.0000\n",
      "Training time: 600.56 sec\n",
      "Trainable parameters: 0.59M\n",
      "CUDA memory used: 2261.26MB\n",
      "\n",
      "R =  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,184,262 || all params: 110,671,116 || trainable%: 1.0701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 09:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.792026</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.519773</td>\n",
       "      <td>0.599064</td>\n",
       "      <td>0.509023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.589300</td>\n",
       "      <td>0.479882</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>0.742592</td>\n",
       "      <td>0.828113</td>\n",
       "      <td>0.768598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.349261</td>\n",
       "      <td>0.881500</td>\n",
       "      <td>0.819278</td>\n",
       "      <td>0.861330</td>\n",
       "      <td>0.833802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.302012</td>\n",
       "      <td>0.903500</td>\n",
       "      <td>0.852311</td>\n",
       "      <td>0.884547</td>\n",
       "      <td>0.863085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>0.255239</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>0.882375</td>\n",
       "      <td>0.892404</td>\n",
       "      <td>0.886842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.276300</td>\n",
       "      <td>0.228059</td>\n",
       "      <td>0.924500</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>0.896372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.226438</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.884114</td>\n",
       "      <td>0.899102</td>\n",
       "      <td>0.890812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.218678</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.902240</td>\n",
       "      <td>0.901802</td>\n",
       "      <td>0.901742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.214966</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.894088</td>\n",
       "      <td>0.902111</td>\n",
       "      <td>0.897574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.212875</td>\n",
       "      <td>0.929500</td>\n",
       "      <td>0.903179</td>\n",
       "      <td>0.902830</td>\n",
       "      <td>0.902605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.2169\n",
      "eval_Accuracy: 0.9245\n",
      "eval_Recall: 0.8780\n",
      "eval_Precision: 0.8919\n",
      "eval_F1: 0.8833\n",
      "eval_runtime: 3.3303\n",
      "eval_samples_per_second: 600.5430\n",
      "eval_steps_per_second: 9.6090\n",
      "epoch: 10.0000\n",
      "Training time: 597.98 sec\n",
      "Trainable parameters: 1.18M\n",
      "CUDA memory used: 2265.72MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in [2, 4, 8, 16, 32]:\n",
    "    print(\"R = \", r)\n",
    "    lora_config = LoraConfig(task_type=TaskType.SEQ_CLS, r=r)\n",
    "\n",
    "    lora_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    lora_model = get_peft_model(lora_model, lora_config)\n",
    "    lora_model.print_trainable_parameters()\n",
    "\n",
    "    lora_model.to(device)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=lora_model,\n",
    "        args=args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"validation\"],\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    train_and_pretty_print_results(trainer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e99f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_78c1d_row3_col5, #T_78c1d_row4_col3, #T_78c1d_row4_col4, #T_78c1d_row4_col6 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_78c1d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_78c1d_level0_col0\" class=\"col_heading level0 col0\" >R</th>\n",
       "      <th id=\"T_78c1d_level0_col1\" class=\"col_heading level0 col1\" >Trainable Params (M)</th>\n",
       "      <th id=\"T_78c1d_level0_col2\" class=\"col_heading level0 col2\" >Trainable %</th>\n",
       "      <th id=\"T_78c1d_level0_col3\" class=\"col_heading level0 col3\" >Accuracy</th>\n",
       "      <th id=\"T_78c1d_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_78c1d_level0_col5\" class=\"col_heading level0 col5\" >Precision</th>\n",
       "      <th id=\"T_78c1d_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
       "      <th id=\"T_78c1d_level0_col7\" class=\"col_heading level0 col7\" >Training Time (s)</th>\n",
       "      <th id=\"T_78c1d_level0_col8\" class=\"col_heading level0 col8\" >Eval Time (s)</th>\n",
       "      <th id=\"T_78c1d_level0_col9\" class=\"col_heading level0 col9\" >CUDA Memory (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_78c1d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_78c1d_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_78c1d_row0_col1\" class=\"data row0 col1\" >0.080000</td>\n",
       "      <td id=\"T_78c1d_row0_col2\" class=\"data row0 col2\" >0.071500</td>\n",
       "      <td id=\"T_78c1d_row0_col3\" class=\"data row0 col3\" >0.918000</td>\n",
       "      <td id=\"T_78c1d_row0_col4\" class=\"data row0 col4\" >0.865700</td>\n",
       "      <td id=\"T_78c1d_row0_col5\" class=\"data row0 col5\" >0.879200</td>\n",
       "      <td id=\"T_78c1d_row0_col6\" class=\"data row0 col6\" >0.871700</td>\n",
       "      <td id=\"T_78c1d_row0_col7\" class=\"data row0 col7\" >595.340000</td>\n",
       "      <td id=\"T_78c1d_row0_col8\" class=\"data row0 col8\" >3.336600</td>\n",
       "      <td id=\"T_78c1d_row0_col9\" class=\"data row0 col9\" >2260.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78c1d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_78c1d_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "      <td id=\"T_78c1d_row1_col1\" class=\"data row1 col1\" >0.150000</td>\n",
       "      <td id=\"T_78c1d_row1_col2\" class=\"data row1 col2\" >0.138700</td>\n",
       "      <td id=\"T_78c1d_row1_col3\" class=\"data row1 col3\" >0.922000</td>\n",
       "      <td id=\"T_78c1d_row1_col4\" class=\"data row1 col4\" >0.875500</td>\n",
       "      <td id=\"T_78c1d_row1_col5\" class=\"data row1 col5\" >0.880100</td>\n",
       "      <td id=\"T_78c1d_row1_col6\" class=\"data row1 col6\" >0.876400</td>\n",
       "      <td id=\"T_78c1d_row1_col7\" class=\"data row1 col7\" >596.710000</td>\n",
       "      <td id=\"T_78c1d_row1_col8\" class=\"data row1 col8\" >3.330000</td>\n",
       "      <td id=\"T_78c1d_row1_col9\" class=\"data row1 col9\" >2254.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78c1d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_78c1d_row2_col0\" class=\"data row2 col0\" >8</td>\n",
       "      <td id=\"T_78c1d_row2_col1\" class=\"data row2 col1\" >0.300000</td>\n",
       "      <td id=\"T_78c1d_row2_col2\" class=\"data row2 col2\" >0.272800</td>\n",
       "      <td id=\"T_78c1d_row2_col3\" class=\"data row2 col3\" >0.921500</td>\n",
       "      <td id=\"T_78c1d_row2_col4\" class=\"data row2 col4\" >0.872900</td>\n",
       "      <td id=\"T_78c1d_row2_col5\" class=\"data row2 col5\" >0.887100</td>\n",
       "      <td id=\"T_78c1d_row2_col6\" class=\"data row2 col6\" >0.878000</td>\n",
       "      <td id=\"T_78c1d_row2_col7\" class=\"data row2 col7\" >599.530000</td>\n",
       "      <td id=\"T_78c1d_row2_col8\" class=\"data row2 col8\" >3.313700</td>\n",
       "      <td id=\"T_78c1d_row2_col9\" class=\"data row2 col9\" >2254.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78c1d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_78c1d_row3_col0\" class=\"data row3 col0\" >16</td>\n",
       "      <td id=\"T_78c1d_row3_col1\" class=\"data row3 col1\" >0.590000</td>\n",
       "      <td id=\"T_78c1d_row3_col2\" class=\"data row3 col2\" >0.540000</td>\n",
       "      <td id=\"T_78c1d_row3_col3\" class=\"data row3 col3\" >0.922000</td>\n",
       "      <td id=\"T_78c1d_row3_col4\" class=\"data row3 col4\" >0.873300</td>\n",
       "      <td id=\"T_78c1d_row3_col5\" class=\"data row3 col5\" >0.893400</td>\n",
       "      <td id=\"T_78c1d_row3_col6\" class=\"data row3 col6\" >0.879300</td>\n",
       "      <td id=\"T_78c1d_row3_col7\" class=\"data row3 col7\" >600.560000</td>\n",
       "      <td id=\"T_78c1d_row3_col8\" class=\"data row3 col8\" >3.309200</td>\n",
       "      <td id=\"T_78c1d_row3_col9\" class=\"data row3 col9\" >2261.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_78c1d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_78c1d_row4_col0\" class=\"data row4 col0\" >32</td>\n",
       "      <td id=\"T_78c1d_row4_col1\" class=\"data row4 col1\" >1.180000</td>\n",
       "      <td id=\"T_78c1d_row4_col2\" class=\"data row4 col2\" >1.070100</td>\n",
       "      <td id=\"T_78c1d_row4_col3\" class=\"data row4 col3\" >0.924500</td>\n",
       "      <td id=\"T_78c1d_row4_col4\" class=\"data row4 col4\" >0.878000</td>\n",
       "      <td id=\"T_78c1d_row4_col5\" class=\"data row4 col5\" >0.891900</td>\n",
       "      <td id=\"T_78c1d_row4_col6\" class=\"data row4 col6\" >0.883300</td>\n",
       "      <td id=\"T_78c1d_row4_col7\" class=\"data row4 col7\" >597.980000</td>\n",
       "      <td id=\"T_78c1d_row4_col8\" class=\"data row4 col8\" >3.330300</td>\n",
       "      <td id=\"T_78c1d_row4_col9\" class=\"data row4 col9\" >2265.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x265a5f33920>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"R\": 2,\n",
    "        \"Trainable Params (M)\": 0.08,\n",
    "        \"Trainable %\": 0.0715,\n",
    "        \"Accuracy\": 0.9180,\n",
    "        \"Recall\": 0.8657,\n",
    "        \"Precision\": 0.8792,\n",
    "        \"F1\": 0.8717,\n",
    "        \"Training Time (s)\": 595.34,\n",
    "        \"Eval Time (s)\": 3.3366,\n",
    "        \"CUDA Memory (MB)\": 2260.31,\n",
    "    },\n",
    "    {\n",
    "        \"R\": 4,\n",
    "        \"Trainable Params (M)\": 0.15,\n",
    "        \"Trainable %\": 0.1387,\n",
    "        \"Accuracy\": 0.9220,\n",
    "        \"Recall\": 0.8755,\n",
    "        \"Precision\": 0.8801,\n",
    "        \"F1\": 0.8764,\n",
    "        \"Training Time (s)\": 596.71,\n",
    "        \"Eval Time (s)\": 3.3300,\n",
    "        \"CUDA Memory (MB)\": 2254.64,\n",
    "    },\n",
    "    {\n",
    "        \"R\": 8,\n",
    "        \"Trainable Params (M)\": 0.30,\n",
    "        \"Trainable %\": 0.2728,\n",
    "        \"Accuracy\": 0.9215,\n",
    "        \"Recall\": 0.8729,\n",
    "        \"Precision\": 0.8871,\n",
    "        \"F1\": 0.8780,\n",
    "        \"Training Time (s)\": 599.53,\n",
    "        \"Eval Time (s)\": 3.3137,\n",
    "        \"CUDA Memory (MB)\": 2254.84,\n",
    "    },\n",
    "    {\n",
    "        \"R\": 16,\n",
    "        \"Trainable Params (M)\": 0.59,\n",
    "        \"Trainable %\": 0.5400,\n",
    "        \"Accuracy\": 0.9220,\n",
    "        \"Recall\": 0.8733,\n",
    "        \"Precision\": 0.8934,\n",
    "        \"F1\": 0.8793,\n",
    "        \"Training Time (s)\": 600.56,\n",
    "        \"Eval Time (s)\": 3.3092,\n",
    "        \"CUDA Memory (MB)\": 2261.26,\n",
    "    },\n",
    "    {\n",
    "        \"R\": 32,\n",
    "        \"Trainable Params (M)\": 1.18,\n",
    "        \"Trainable %\": 1.0701,\n",
    "        \"Accuracy\": 0.9245,\n",
    "        \"Recall\": 0.8780,\n",
    "        \"Precision\": 0.8919,\n",
    "        \"F1\": 0.8833,\n",
    "        \"Training Time (s)\": 597.98,\n",
    "        \"Eval Time (s)\": 3.3303,\n",
    "        \"CUDA Memory (MB)\": 2265.72,\n",
    "    },\n",
    "]\n",
    "\n",
    "df_lora = pd.DataFrame(data)\n",
    "df_lora = df_lora.style.highlight_max(subset=[\"Accuracy\", \"Recall\", \"Precision\", \"F1\"], color=\"green\")\n",
    "df_lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d3462",
   "metadata": {},
   "source": [
    "- качество постепенно растёт с увеличением r, но после r=16 — почти не меняется\n",
    "\n",
    "- при r=32 достигается лучший F1 = 0.8833, но прирост незначителен по сравнению с r=16\n",
    "\n",
    "- использование GPU памяти почти не растёт, что делает LoRA очень экономичным\n",
    "\n",
    "- даже при r=32 обучается только 1.07% параметров модели (~1.18M из 110M)\n",
    "\n",
    "- если важна эффективность, оптимальным можно считать r=8 или r=16\n",
    "\n",
    "- r=2 — самый лёгкий, но теряет 1.1% F1 по сравнению с r=32\n",
    "\n",
    "- в итоге я бы все равно выбрала как итоговый вариант r=32, так как его метрики лучше, хоть и незначительно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4eee78",
   "metadata": {},
   "source": [
    "# 6. Итоговое сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04df34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f1ee2_row0_col6, #T_f1ee2_row1_col2, #T_f1ee2_row1_col3, #T_f1ee2_row1_col6, #T_f1ee2_row2_col5, #T_f1ee2_row2_col7, #T_f1ee2_row5_col1, #T_f1ee2_row5_col4 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f1ee2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f1ee2_level0_col0\" class=\"col_heading level0 col0\" >method</th>\n",
       "      <th id=\"T_f1ee2_level0_col1\" class=\"col_heading level0 col1\" >accuracy</th>\n",
       "      <th id=\"T_f1ee2_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
       "      <th id=\"T_f1ee2_level0_col3\" class=\"col_heading level0 col3\" >precision</th>\n",
       "      <th id=\"T_f1ee2_level0_col4\" class=\"col_heading level0 col4\" >f1</th>\n",
       "      <th id=\"T_f1ee2_level0_col5\" class=\"col_heading level0 col5\" >trainable_params_M</th>\n",
       "      <th id=\"T_f1ee2_level0_col6\" class=\"col_heading level0 col6\" >cuda_mem_MB</th>\n",
       "      <th id=\"T_f1ee2_level0_col7\" class=\"col_heading level0 col7\" >training_time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f1ee2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f1ee2_row0_col0\" class=\"data row0 col0\" >no finetuning</td>\n",
       "      <td id=\"T_f1ee2_row0_col1\" class=\"data row0 col1\" >0.5775</td>\n",
       "      <td id=\"T_f1ee2_row0_col2\" class=\"data row0 col2\" >0.3039</td>\n",
       "      <td id=\"T_f1ee2_row0_col3\" class=\"data row0 col3\" >0.2751</td>\n",
       "      <td id=\"T_f1ee2_row0_col4\" class=\"data row0 col4\" >0.2425</td>\n",
       "      <td id=\"T_f1ee2_row0_col5\" class=\"data row0 col5\" >109.4900</td>\n",
       "      <td id=\"T_f1ee2_row0_col6\" class=\"data row0 col6\" >1334.2500</td>\n",
       "      <td id=\"T_f1ee2_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1ee2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f1ee2_row1_col0\" class=\"data row1 col0\" >finetuning</td>\n",
       "      <td id=\"T_f1ee2_row1_col1\" class=\"data row1 col1\" >0.9235</td>\n",
       "      <td id=\"T_f1ee2_row1_col2\" class=\"data row1 col2\" >0.8891</td>\n",
       "      <td id=\"T_f1ee2_row1_col3\" class=\"data row1 col3\" >0.8951</td>\n",
       "      <td id=\"T_f1ee2_row1_col4\" class=\"data row1 col4\" >0.8823</td>\n",
       "      <td id=\"T_f1ee2_row1_col5\" class=\"data row1 col5\" >109.4900</td>\n",
       "      <td id=\"T_f1ee2_row1_col6\" class=\"data row1 col6\" >1334.2500</td>\n",
       "      <td id=\"T_f1ee2_row1_col7\" class=\"data row1 col7\" >1127.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1ee2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f1ee2_row2_col0\" class=\"data row2 col0\" >linear probing</td>\n",
       "      <td id=\"T_f1ee2_row2_col1\" class=\"data row2 col1\" >0.4645</td>\n",
       "      <td id=\"T_f1ee2_row2_col2\" class=\"data row2 col2\" >0.2388</td>\n",
       "      <td id=\"T_f1ee2_row2_col3\" class=\"data row2 col3\" >0.1532</td>\n",
       "      <td id=\"T_f1ee2_row2_col4\" class=\"data row2 col4\" >0.1858</td>\n",
       "      <td id=\"T_f1ee2_row2_col5\" class=\"data row2 col5\" >0.0000</td>\n",
       "      <td id=\"T_f1ee2_row2_col6\" class=\"data row2 col6\" >1774.0600</td>\n",
       "      <td id=\"T_f1ee2_row2_col7\" class=\"data row2 col7\" >315.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1ee2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f1ee2_row3_col0\" class=\"data row3 col0\" >prefix tuning</td>\n",
       "      <td id=\"T_f1ee2_row3_col1\" class=\"data row3 col1\" >0.3820</td>\n",
       "      <td id=\"T_f1ee2_row3_col2\" class=\"data row3 col2\" >0.1901</td>\n",
       "      <td id=\"T_f1ee2_row3_col3\" class=\"data row3 col3\" >0.1284</td>\n",
       "      <td id=\"T_f1ee2_row3_col4\" class=\"data row3 col4\" >0.1400</td>\n",
       "      <td id=\"T_f1ee2_row3_col5\" class=\"data row3 col5\" >0.3700</td>\n",
       "      <td id=\"T_f1ee2_row3_col6\" class=\"data row3 col6\" >2256.8500</td>\n",
       "      <td id=\"T_f1ee2_row3_col7\" class=\"data row3 col7\" >581.8100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1ee2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f1ee2_row4_col0\" class=\"data row4 col0\" >prompt tuning</td>\n",
       "      <td id=\"T_f1ee2_row4_col1\" class=\"data row4 col1\" >0.4750</td>\n",
       "      <td id=\"T_f1ee2_row4_col2\" class=\"data row4 col2\" >0.2989</td>\n",
       "      <td id=\"T_f1ee2_row4_col3\" class=\"data row4 col3\" >0.2231</td>\n",
       "      <td id=\"T_f1ee2_row4_col4\" class=\"data row4 col4\" >0.2508</td>\n",
       "      <td id=\"T_f1ee2_row4_col5\" class=\"data row4 col5\" >0.0200</td>\n",
       "      <td id=\"T_f1ee2_row4_col6\" class=\"data row4 col6\" >1804.1400</td>\n",
       "      <td id=\"T_f1ee2_row4_col7\" class=\"data row4 col7\" >780.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1ee2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f1ee2_row5_col0\" class=\"data row5 col0\" >LoRA_r32</td>\n",
       "      <td id=\"T_f1ee2_row5_col1\" class=\"data row5 col1\" >0.9245</td>\n",
       "      <td id=\"T_f1ee2_row5_col2\" class=\"data row5 col2\" >0.8780</td>\n",
       "      <td id=\"T_f1ee2_row5_col3\" class=\"data row5 col3\" >0.8919</td>\n",
       "      <td id=\"T_f1ee2_row5_col4\" class=\"data row5 col4\" >0.8833</td>\n",
       "      <td id=\"T_f1ee2_row5_col5\" class=\"data row5 col5\" >1.1800</td>\n",
       "      <td id=\"T_f1ee2_row5_col6\" class=\"data row5 col6\" >2265.7200</td>\n",
       "      <td id=\"T_f1ee2_row5_col7\" class=\"data row5 col7\" >597.9800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x265b1e70d10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"method\": [\"no finetuning\", \"finetuning\", \"linear probing\", \"prefix tuning\", \"prompt tuning\", \"LoRA_r32\"],\n",
    "    \"accuracy\": [0.5775, 0.9235, 0.4645, 0.3820, 0.4750, 0.9245],\n",
    "    \"recall\": [0.3039, 0.8891, 0.2388, 0.1901, 0.2989, 0.8780],\n",
    "    \"precision\": [0.2751, 0.8951, 0.1532, 0.1284, 0.2231, 0.8919],\n",
    "    \"f1\": [0.2425, 0.8823, 0.1858, 0.1400, 0.2508, 0.8833],\n",
    "    \"trainable_params_M\": [109.49, 109.49, 0.00, 0.37, 0.02, 1.18],\n",
    "    \"cuda_mem_MB\": [1334.25, 1334.25, 1774.06, 2256.85, 1804.14, 2265.72],\n",
    "    \"training_time_sec\": [None, 1127.64, 315.08, 581.81, 780.66, 597.98],\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(data)\n",
    "result_df = (\n",
    "    result_df.style.format(precision=4)\n",
    "    .highlight_max(subset=[\"accuracy\", \"recall\", \"precision\", \"f1\"], color=\"green\")\n",
    "    .highlight_min(subset=[\"trainable_params_M\", \"cuda_mem_MB\", \"training_time_sec\"], color=\"green\")\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161d23f0",
   "metadata": {},
   "source": [
    "### коротко про результаты:\n",
    "- лучшие метрики показал LoRA_r32 — чуть выше по всем показателям, чем полное fine-tuning, особенно по F1 (0.8833 против 0.8823). при этом обучается он почти в 2 раза быстрее (598 сек против 1128) и требует в 100 раз меньше параметров (1.18М vs 109.49М).\n",
    "\n",
    "- fine-tuning тоже мощный, но дорогой и тяжёлый. много параметров, долго обучается.\n",
    "\n",
    "- prompt tuning оказался лучше, чем linear и prefix tuning, но всё равно F1 у него всего 0.25 — слабо.\n",
    "\n",
    "- prefix tuning и linear probing — худшие по всем метрикам. особенно precision: 0.128 и 0.153 соответственно.\n",
    "\n",
    "- no finetuning удивительно дал F1 выше, чем prefix tuning и linear probing — то есть лучше вообще ничего не трогать, чем использовать эти два. либо досконально настраивать параметры, так как я использовала одинаковые для всех.\n",
    "\n",
    "- в целом, LoRA показала себя лучше всех — почти как фулл fine-tuning, но сильно легче в ресурсах."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
