{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Домашнее задание 3 - 10 баллов**\n",
    "\n",
    "В этом задании вам предстоит продолжить работу с зачадей машинного перевода из занятия 7.\n",
    "\n",
    "Попробуйте улучшить качество модели, проверив следующие гипотезы:\n",
    "\n",
    "- измените размер словаря / предобработку во время токенизации - **1 балл**\n",
    "- продолжите эксперименты с различными RNN юнитами в encoder и decoder части: замена GRU/LSTM, изменение количества слоев, использование bidirectional RNN - **1 балл**\n",
    "- улучшите процесс тренировки: добавьте lr sheduling, early stopping, поэкспериментируйте с оптимизатором - **2 балла**\n",
    "- поэкспериментируйте с сэмплированием - замените greedy-инференс на альтернативные варианты - **2 балла**\n",
    "- проведите ablation-study, сделайте выводы о влиянии ваших изменений на итоговую производительность модели - **2 балла**\n",
    "\n",
    "**Общее**\n",
    "\n",
    "- Принимаемые решения обоснованы (почему выбрана определенная архитектура/гиперпараметр/оптимизатор/преобразование и т.п.) - **1 балл**\n",
    "- Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **1 балл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tokenizers import Tokenizer, trainers, models, pre_tokenizers, decoders, processors\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cordelia Hotel is situated in Tbilisi, a 3-minute walk away from Saint Trinity Church.\tОтель Cordelia расположен в Тбилиси, в 3 минутах ходьбы от Свято-Троицкого собора.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/data.txt', encoding='utf-8') as f:\n",
    "    print(f.readlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def tokenize(x):\n",
    "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
    "\n",
    "\n",
    "with open('data/train.en', 'w', encoding='utf-8') as f_src, open('data/train.ru', 'w', encoding='utf-8') as f_dst:\n",
    "    for line in open('data/data.txt', encoding='utf-8'):\n",
    "        src_line, dst_line = line.strip().split('\\t')\n",
    "        f_src.write(tokenize(src_line) + '\\n')\n",
    "        f_dst.write(tokenize(dst_line) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение токенайзеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe_tokenizer(dataset, vocab_size=10000):\n",
    "    tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size, special_tokens=['[PAD]', '[SOS]', '[EOS]', '[UNK]'], end_of_word_suffix='##'\n",
    "    )\n",
    "    tokenizer.train_from_iterator(dataset, trainer)\n",
    "\n",
    "    sos_token_id = tokenizer.token_to_id('[SOS]')\n",
    "    eos_token_id = tokenizer.token_to_id('[EOS]')\n",
    "\n",
    "    tokenizer.post_processor = processors.TemplateProcessing(\n",
    "        single=f'[SOS] $A [EOS]',\n",
    "        special_tokens=[('[SOS]', sos_token_id), ('[EOS]', eos_token_id)],\n",
    "    )\n",
    "\n",
    "    tokenizer.decoder = decoders.BPEDecoder(suffix='##')\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[SOS]', 'ex', 'ample##', 'tex', 't##', 'in##', 'tar', 'get##', 'langu', 'age##', '[EOS]']\n",
      "['[SOS]', 'пример##', 'тек', 'ста##', 'на##', 'ис', 'ход', 'ном##', 'язы', 'ке##', '[EOS]']\n"
     ]
    }
   ],
   "source": [
    "src_texts = np.array(open('data/train.ru', encoding='utf-8').read().split('\\n'))\n",
    "tgt_texts = np.array(open('data/train.en', encoding='utf-8').read().split('\\n'))\n",
    "\n",
    "train_src, test_src, train_tgt, test_tgt = train_test_split(\n",
    "    src_texts,\n",
    "    tgt_texts,\n",
    "    test_size=3000,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "src_tokenizer = train_bpe_tokenizer(src_texts)\n",
    "tgt_tokenizer = train_bpe_tokenizer(tgt_texts)\n",
    "\n",
    "print(tgt_tokenizer.encode('example text in target language').tokens)\n",
    "print(src_tokenizer.encode('пример текста на исходном языке').tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 623, 2641, 4010, 190, 320, 2203, 2073, 7864, 645, 2]\n",
      "[1, 4996, 2700, 2379, 338, 1313, 538, 395, 4333, 719, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tgt_tokenizer.encode('example text in target language').ids)\n",
    "print(src_tokenizer.encode('пример текста на исходном языке').ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example text in target language\n"
     ]
    }
   ],
   "source": [
    "print(tgt_tokenizer.decode(tgt_tokenizer.encode('example text in target language').ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vocab_size in [1000, 5000, 10000]:\n",
    "    src_tokenizer = train_bpe_tokenizer(src_texts, vocab_size=vocab_size)\n",
    "    tgt_tokenizer = train_bpe_tokenizer(tgt_texts, vocab_size=vocab_size)\n",
    "\n",
    "    src_tokenizer.save(f'tokenizers/bpe_ru_{vocab_size}.json')\n",
    "    tgt_tokenizer.save(f'tokenizers/bpe_en_{vocab_size}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('source length')\n",
    "plt.hist(list(map(len, map(str.split, src_texts))), bins=20)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('translation length')\n",
    "plt.hist(list(map(len, map(str.split, tgt_texts))), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_texts, tgt_texts, src_tokenizer, tgt_tokenizer):\n",
    "        self.src_texts = src_texts\n",
    "        self.tgt_texts = tgt_texts\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        self.PAD_TOKEN_ID = src_tokenizer.token_to_id('[PAD]')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_texts)\n",
    "\n",
    "    def encode(self, text, tokenizer):\n",
    "        tokens = tokenizer.encode(text).ids\n",
    "        return tokens\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.encode(self.src_texts[idx], self.src_tokenizer)\n",
    "        tgt = self.encode(self.tgt_texts[idx], self.tgt_tokenizer)\n",
    "        return torch.tensor(src), torch.tensor(tgt)\n",
    "\n",
    "\n",
    "def collate_pad_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    PAD_TOKEN_ID = batch[0][0].new_tensor(src_tokenizer.token_to_id('[EOS]'))\n",
    "    # на самом деле должен быть [PAD], но ориентируюсь на код с пары\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "train_dataset = TranslationDataset(train_src, train_tgt, src_tokenizer, tgt_tokenizer)\n",
    "test_dataset = TranslationDataset(test_src, test_tgt, src_tokenizer, tgt_tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=collate_pad_fn)\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=False, collate_fn=collate_pad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, enc_size, dec_size, hid_size):\n",
    "        super().__init__()\n",
    "        self.linear_enc = nn.Linear(enc_size, hid_size)\n",
    "        self.linear_dec = nn.Linear(dec_size, hid_size)\n",
    "        self.linear_out = nn.Linear(hid_size, 1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, enc, dec, inp_mask):\n",
    "        batch_size, ninp, _ = enc.shape\n",
    "        x = self.linear_dec(dec).unsqueeze(1) + self.linear_enc(enc)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.linear_out(x).squeeze(-1)\n",
    "        x = torch.where(inp_mask, x, torch.tensor(-1e9, device=x.device))\n",
    "        probs = self.softmax(x)\n",
    "        attn = torch.sum(probs.unsqueeze(-1) * enc, dim=1)\n",
    "        return attn, probs\n",
    "\n",
    "\n",
    "class AttentiveModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_tokenizer,\n",
    "        tgt_tokenizer,\n",
    "        emb_size=64,\n",
    "        hid_size=128,\n",
    "        attn_size=128,\n",
    "        src_vocab_size=10000,\n",
    "        tgt_vocab_size=10000,\n",
    "        eos_idx=2,\n",
    "        sos_idx=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.src_tokenizer, self.tgt_tokenizer = src_tokenizer, tgt_tokenizer\n",
    "\n",
    "        self.src_vocab_size = src_tokenizer.get_vocab_size()\n",
    "        self.tgt_vocab_size = tgt_tokenizer.get_vocab_size()\n",
    "        self.eos_idx = src_tokenizer.token_to_id('[EOS]')\n",
    "        self.sos_idx = src_tokenizer.token_to_id('[EOS]')\n",
    "\n",
    "        self.hid_size = hid_size\n",
    "\n",
    "        self.emb_inp = nn.Embedding(self.src_vocab_size, emb_size)\n",
    "        self.emb_out = nn.Embedding(self.tgt_vocab_size, emb_size)\n",
    "        self.enc0 = nn.LSTM(emb_size, hid_size, num_layers=2, batch_first=True)\n",
    "        self.dec_start = nn.Linear(hid_size, hid_size)\n",
    "        self.dec0 = nn.GRUCell(emb_size + hid_size, hid_size)\n",
    "        self.attention = AttentionLayer(hid_size, hid_size, attn_size)\n",
    "        self.logits = nn.Linear(hid_size, self.tgt_vocab_size)\n",
    "\n",
    "    def encode(self, inp):\n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        enc_seq, _ = self.enc0(inp_emb)\n",
    "        lengths = (inp != self.eos_idx).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 1)\n",
    "        last_state = enc_seq[torch.arange(len(enc_seq)), lengths]\n",
    "        dec_start = self.dec_start(last_state)\n",
    "        inp_mask = inp != self.eos_idx\n",
    "        first_attn_probas = self.attention(enc_seq, dec_start, inp_mask)[1]\n",
    "        return [dec_start, enc_seq, inp_mask, first_attn_probas]\n",
    "\n",
    "    def decode_step(self, prev_state, prev_tokens):\n",
    "        prev_gru0_state, enc_seq, enc_mask, _ = prev_state\n",
    "        attn, attn_probs = self.attention(enc_seq, prev_gru0_state, enc_mask)\n",
    "        x = torch.cat([attn, self.emb_out(prev_tokens)], dim=-1)\n",
    "        x = self.dec0(x, prev_gru0_state)\n",
    "        return [x, enc_seq, enc_mask, attn_probs], self.logits(x)\n",
    "\n",
    "    def decode(self, initial_state, out_tokens):\n",
    "        batch_size = out_tokens.shape[0]\n",
    "        state = initial_state\n",
    "\n",
    "        # initial logits: always predict BOS\n",
    "        onehot_bos = F.one_hot(\n",
    "            torch.full([batch_size], self.sos_idx, dtype=torch.int64),\n",
    "            num_classes=self.src_vocab_size,\n",
    "        ).to(device=out_tokens.device)\n",
    "        first_logits = torch.log(onehot_bos.to(torch.float32) + 1e-9)\n",
    "\n",
    "        logits_sequence = [first_logits]\n",
    "\n",
    "        for i in range(out_tokens.shape[1] - 1):\n",
    "            state, logits = self.decode_step(state, out_tokens[:, i])\n",
    "            logits_sequence.append(logits)\n",
    "        return torch.stack(logits_sequence, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inp, out = batch\n",
    "        initial_state = self.encode(inp)\n",
    "        logits = self.decode(initial_state, out)\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), out.view(-1), ignore_index=self.eos_idx)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inp, out = batch\n",
    "        initial_state = self.encode(inp)\n",
    "        logits = self.decode(initial_state, out)\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        references = self.tgt_tokenizer.decode_batch(out.cpu().numpy())\n",
    "        candidates = self.tgt_tokenizer.decode_batch(predictions.cpu().numpy())\n",
    "        bleu = bleu_score(candidates, references)\n",
    "\n",
    "        self.log('test_bleu', bleu, prog_bar=True)\n",
    "        return {'bleu': bleu}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    wandb_logger = WandbLogger(project='AttentionRNN')\n",
    "    early_stop = EarlyStopping(monitor='train_loss', patience=3, mode='min')\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = AttentiveModel(src_tokenizer, tgt_tokenizer)\n",
    "    trainer = L.Trainer(max_epochs=50, callbacks=[early_stop, lr_monitor], logger=wandb_logger, accelerator=device)\n",
    "    trainer.fit(model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | emb_inp   | Embedding      | 640 K  | train\n",
      "1 | emb_out   | Embedding      | 640 K  | train\n",
      "2 | enc0      | LSTM           | 231 K  | train\n",
      "3 | dec_start | Linear         | 16.5 K | train\n",
      "4 | dec0      | GRUCell        | 123 K  | train\n",
      "5 | attention | AttentionLayer | 33.2 K | train\n",
      "6 | logits    | Linear         | 1.3 M  | train\n",
      "-----------------------------------------------------\n",
      "3.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 M     Total params\n",
      "11.899    Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ivawi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\logging\\__init__.py\", line 1163, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\Users\\ivawi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\u0441' in position 1201: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\ivawi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\ivawi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\ivawi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ivawi\\AppData\\Local\\Temp\\ipykernel_27516\\3364925475.py\", line 1, in <module>\n",
      "    train()\n",
      "  File \"C:\\Users\\ivawi\\AppData\\Local\\Temp\\ipykernel_27516\\718081374.py\", line 8, in train\n",
      "    trainer.fit(model, train_dataloader, test_dataloader)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 539, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 575, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 965, in _run\n",
      "    _log_hyperparams(self)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\utilities.py\", line 100, in _log_hyperparams\n",
      "    logger.log_hyperparams(hparams_initial)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning_utilities\\core\\rank_zero.py\", line 42, in wrapped_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py\", line 429, in log_hyperparams\n",
      "    self.experiment.config.update(params, allow_val_change=True)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\wandb\\sdk\\wandb_config.py\", line 189, in update\n",
      "    self._callback(data=sanitized)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 401, in wrapper_fn\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1261, in _config_callback\n",
      "    logger.info(f\"config_cb {key} {val} {data}\")\n",
      "Message: 'config_cb None None {\\'src_tokenizer\\': \\'Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"[PAD]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":1, \"content\":\"[SOS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":2, \"content\":\"[EOS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":3, \"content\":\"[UNK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}], normalizer=None, pre_tokenizer=Whitespace(), post_processor=TemplateProcessing(single=[SpecialToken(id=\"[SOS]\", type_id=0), Sequence(id=A, type_id=0), SpecialToken(id=\"[EOS]\", type_id=0)], pair=[Sequence(id=A, type_id=0), Sequence(id=B, type_id=1)], special_tokens={\"[EOS]\":SpecialToken(id=\"[EOS]\", ids=[2], tokens=[\"[EOS]\"]), \"[SOS]\":SpecialToken(id=\"[SOS]\", ids=[1], tokens=[\"[SOS]\"])}), decoder=BPEDecoder(suffix=\"##\"), model=BPE(dropout=None, unk_token=None, continuing_subword_prefix=None, end_of_word_suffix=\"##\", fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={\"[PAD]\":0, \"[SOS]\":1, \"[EOS]\":2, \"[UNK]\":3, \"\\\\x0f\":4, ...}, merges=[(\"с\", \"т\"), (\"н\", \"о\"), (\"р\", \"а\"), (\"н\", \"а\"), (\"р\", \"о\"), ...]))\\', \\'tgt_tokenizer\\': \\'Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"[PAD]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":1, \"content\":\"[SOS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":2, \"content\":\"[EOS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}, {\"id\":3, \"content\":\"[UNK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, ...}], normalizer=None, pre_tokenizer=Whitespace(), post_processor=TemplateProcessing(single=[SpecialToken(id=\"[SOS]\", type_id=0), Sequence(id=A, type_id=0), SpecialToken(id=\"[EOS]\", type_id=0)], pair=[Sequence(id=A, type_id=0), Sequence(id=B, type_id=1)], special_tokens={\"[EOS]\":SpecialToken(id=\"[EOS]\", ids=[2], tokens=[\"[EOS]\"]), \"[SOS]\":SpecialToken(id=\"[SOS]\", ids=[1], tokens=[\"[SOS]\"])}), decoder=BPEDecoder(suffix=\"##\"), model=BPE(dropout=None, unk_token=None, continuing_subword_prefix=None, end_of_word_suffix=\"##\", fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={\"[PAD]\":0, \"[SOS]\":1, \"[EOS]\":2, \"[UNK]\":3, \"!\":4, ...}, merges=[(\"t\", \"h\"), (\"i\", \"n\"), (\"a\", \"n\"), (\"r\", \"o\"), (\"r\", \"e\"), ...]))\\', \\'emb_size\\': 64, \\'hid_size\\': 128, \\'attn_size\\': 128, \\'src_vocab_size\\': 10000, \\'tgt_vocab_size\\': 10000, \\'eos_idx\\': 2, \\'sos_idx\\': 1}'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52b88106b274c11a299760cb3689945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The length of candidate and reference corpus should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[211], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[210], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m AttentiveModel(src_tokenizer, tgt_tokenizer)\n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[early_stop, lr_monitor], logger\u001b[38;5;241m=\u001b[39mwandb_logger, accelerator\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    571\u001b[0m     ckpt_path,\n\u001b[0;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1024\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1024\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1026\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1050\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:144\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:433\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[0;32m    427\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[0;32m    432\u001b[0m )\n\u001b[1;32m--> 433\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:323\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 323\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    326\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[209], line 104\u001b[0m, in \u001b[0;36mAttentiveModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    102\u001b[0m references \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_tokenizer\u001b[38;5;241m.\u001b[39mdecode_batch(out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    103\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_tokenizer\u001b[38;5;241m.\u001b[39mdecode_batch(predictions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())]\n\u001b[1;32m--> 104\u001b[0m bleu \u001b[38;5;241m=\u001b[39m \u001b[43mbleu_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_bleu\u001b[39m\u001b[38;5;124m'\u001b[39m, bleu, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m'\u001b[39m: bleu}\n",
      "File \u001b[1;32mc:\\Users\\ivawi\\projects\\aith_dl_nlp\\.venv\\Lib\\site-packages\\torchtext\\data\\metrics.py:56\u001b[0m, in \u001b[0;36mbleu_score\u001b[1;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the BLEU score between a candidate translation corpus and a references\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03mtranslation corpus. Based on https://www.aclweb.org/anthology/P02-1040.pdf\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m        0.8408964276313782\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m max_n \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(weights), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLength of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m list has be equal to max_n\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(candidate_corpus) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m     57\u001b[0m     references_corpus\n\u001b[0;32m     58\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of candidate and reference corpus should be the same\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m clipped_counts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(max_n)\n\u001b[0;32m     61\u001b[0m total_counts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(max_n)\n",
      "\u001b[1;31mAssertionError\u001b[0m: The length of candidate and reference corpus should be the same"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_tokenizer = Tokenizer.from_file(\"tokenizers/bpe_ru_1000.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
